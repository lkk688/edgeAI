# Core dependencies
torch>=1.10.0
numpy>=1.20.0
matplotlib>=3.4.0
psutil>=5.8.0
requests>=2.25.0

# For Hugging Face models
transformers>=4.20.0
accelerator>=0.20.0

# For GPU monitoring
gputil>=1.4.0

# For ONNX Runtime (optional)
# onnxruntime>=1.10.0
# onnxruntime-gpu>=1.10.0  # For GPU acceleration

# For llama.cpp Python bindings (optional)
# llama-cpp-python>=0.1.50

# For async batch processing (optional)
aiohttp>=3.8.0
asyncio>=3.4.3

# For quantization support (optional)
bitsandbytes>=0.35.0