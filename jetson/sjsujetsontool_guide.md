# ğŸ§  NVIDIA Jetson Orin Nano Student Guide

**Author:** Kaikai Liu
**Email:** [kaikai.liu@sjsu.edu](mailto:kaikai.liu@sjsu.edu)

---

## ğŸ“Œ Overview

This guide introduces the **NVIDIA Jetson Orin Nano**, explains how to install and use our custom Jetson utility script `sjsujetsontool`, and provides step-by-step instructions for development tasks such as launching servers, running AI models, setting up Jupyter, and managing devices.

---

## ğŸ§  What Is NVIDIA Jetson Orin Nano?

The **Jetson Orin Nano** is a powerful, energy-efficient AI edge computing board by NVIDIA. Key features:

* âœ… 6-core ARM Cortex CPU
* âœ… Ampere GPU with up to 1024 CUDA cores
* âœ… Ideal for robotics, vision, AI model serving, and cyber experiments
* âœ… Supports JetPack SDK with Ubuntu, CUDA, cuDNN, TensorRT

---

## ğŸŒ Connecting to Jetson via `.local` Hostname

Jetson devices with mDNS enabled can be accessed using the `.local` hostname from macOS or Linux:

```bash
ssh username@jetson-hostname.local
```

For example:

```bash
ssh sjsujetson@jetson-01.local
```

> If this doesn't work, make sure `avahi-daemon` is running on Jetson and that your network supports mDNS.

---

## âš™ï¸ Installing `sjsujetsontool`

A command-line tool for Jetson-based workflows: container management, model serving, RAG apps, and more.

### âœ… One-line install (no sudo required)

```bash
curl -fsSL https://raw.githubusercontent.com/lkk688/edgeAI/main/jetson/install_sjsujetsontool.sh | bash
```

Then reload shell:

```bash
source ~/.bashrc  # or ~/.zshrc
```

Verify:

```bash
sjsujetsontool list
```

---

## ğŸ§ª Common Usage Examples

### ğŸŸ¢ `sjsujetsontool jupyter`

Launches JupyterLab on port 8888 from inside the Jetson's Docker container. It allows interactive Python notebooks for AI model testing, data exploration, and debugging.

### ğŸ§  `sjsujetsontool ollama`

Starts the Ollama LLM server inside the container, exposing an OpenAI-compatible API on port 11434. Useful for LangChain and AI chat integration.

### ğŸ”¬ `sjsujetsontool llama`

Starts the `llama.cpp` server (C++ GGUF LLM inference engine) on port 8000. Loads a `.gguf` model and serves an HTTP API for tokenized prompt completion.

### ğŸ `sjsujetsontool run <script.py>`

Runs any Python script inside the preconfigured container. Ensures all ML/AI libraries and GPU drivers are properly set up.

### ğŸš€ `sjsujetsontool fastapi`

Launches a FastAPI backend on port 8001, useful for serving AI endpoints for real-time apps.

### ğŸ“š `sjsujetsontool rag`

Runs a LangChain Retrieval-Augmented Generation demo server with local documents and vector search.

### ğŸ“¦ `sjsujetsontool status`

Displays:

* Docker container state
* GPU stats from `tegrastats`
* Port listening status for key services

### ğŸ”§ `sjsujetsontool set-hostname <name> [github_user]`

Changes device hostname, regenerates system identity, writes `/etc/device-id`, and adds GitHub SSH keys.

### ğŸ” `sjsujetsontool setup-ssh <github_user>`

Fetches the GitHub user's public SSH keys and adds them to `~/.ssh/authorized_keys` for passwordless SSH login.

### ğŸ“ `sjsujetsontool mount-nfs <host> <remote_path> <mount_point>`

Mounts a shared folder from a remote NFS server. Useful for accessing centralized data or logging remotely.

### ğŸ› ï¸ `sjsujetsontool build`

Rebuilds the base development Docker image with CUDA, Python, PyTorch, and other libraries pre-installed.

### ğŸ›‘ `sjsujetsontool stop`

Stops the running Docker container started by previous commands.

### ğŸ§¾ `sjsujetsontool update`

Downloads the latest version of `sjsujetsontool` from GitHub and replaces the local version, keeping a backup.

### ğŸ“‹ `sjsujetsontool list`

Displays all available commands with usage examples.

---

## âš ï¸ Safety Guidelines

* ğŸ”Œ **Power Supply**: Use a 5A USB-C adapter or official barrel jack for stability.
* ğŸ’¾ **SSD Cloning**: Change the hostname and machine-id after cloning to prevent network conflicts.
* ğŸ” **SSH Security**: Only install SSH keys from trusted GitHub accounts.
* ğŸ§¼ **Disk Cleanup**: Remove cache and large datasets before creating system images.
* ğŸ“¦ **Containers**: Always stop containers with `sjsujetsontool stop` before unplugging.

---

## ğŸ§­ Ready to Learn and Build

You're now equipped to:

* Run AI models (LLaMA, Mistral, DeepSeek, etc.)
* Build and test FastAPI/LLM applications
* Access Jetson remotely with SSH or VS Code
* Run real-time cyber/AI experiments on the edge!

---

Made with ğŸ’» by [Kaikai Liu](mailto:kaikai.liu@sjsu.edu) â€” [GitHub Repo](https://github.com/lkk688/edgeAI)
