
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../08_prompt_engineering_langchain_jetson/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>ğŸ” RAG Applications with LangChain - Jetson Cyber & AI Summer Camp</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#rag-applications-with-langchain-on-jetson" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Jetson Cyber &amp; AI Summer Camp" class="md-header__button md-logo" aria-label="Jetson Cyber & AI Summer Camp" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Jetson Cyber & AI Summer Camp
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ğŸ” RAG Applications with LangChain
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Jetson Cyber &amp; AI Summer Camp" class="md-nav__button md-logo" aria-label="Jetson Cyber & AI Summer Camp" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Jetson Cyber & AI Summer Camp
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ğŸ”° Getting Started with Jetson
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            ğŸ”° Getting Started with Jetson
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00_sjsujetsontool_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    âœ… sjsujetsontool Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00b_sjsujetsontool_cheatsheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸ“‹ sjsujetsontool Cheatsheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01a_nvidia_jetson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸ”§ Introduction to NVIDIA Jetson
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01b_jetson_cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸš€ CUDA Programming on Jetson
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ğŸ§ Linux Fundamentals
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            ğŸ§ Linux Fundamentals
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02a_linux_basics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸ’¡ Linux OS Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03a_linux_networking_tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸŒ Linux Networking Tools
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ğŸ¤– AI & LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            ğŸ¤– AI & LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04_deeplearning_cnn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸ§  Deep Learning & CNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_transformers_nlp_applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸ§  Transformers & NLP Applications
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_llms_jetson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸš€ Large Language Models on Jetson
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07_nlp_applications_llm_optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ğŸ“š NLP Applications & LLM Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08_prompt_engineering_langchain_jetson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    âœï¸ Prompt Engineering & LangChain
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    ğŸ” RAG Applications with LangChain
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    ğŸ” RAG Applications with LangChain
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-rag" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¤” What is RAG?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¤” What is RAG?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-technology-behind-rag" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¬ The Technology Behind RAG
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”¬ The Technology Behind RAG">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-components" class="md-nav__link">
    <span class="md-ellipsis">
      Core Components:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rag-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      RAG Workflow:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§  Understanding Embeddings
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ§  Understanding Embeddings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-properties" class="md-nav__link">
    <span class="md-ellipsis">
      Key Properties:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-embedding-models" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Embedding Models:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-rag-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ’¡ Why RAG on Jetson?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ’¡ Why RAG on Jetson?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-ai-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      Edge AI Advantages:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jetson-specific-benefits" class="md-nav__link">
    <span class="md-ellipsis">
      Jetson-Specific Benefits:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-rag-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ Advanced RAG Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”§ Advanced RAG Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rag-pipeline-components" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š RAG Pipeline Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detailed-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ—ï¸ Detailed Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rag-optimization-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¯ RAG Optimization Strategies
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¯ RAG Optimization Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chunking-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Chunking Strategies:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retrieval-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval Strategies:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-enhancement" class="md-nav__link">
    <span class="md-ellipsis">
      Context Enhancement:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-components-in-langchain" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§± Key Components in LangChain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#embedding-models-evaluation-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ Embedding Models Evaluation on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸš€ Embedding Models Evaluation on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embedding-model-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“‹ Embedding Model Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding-models-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¬ Embedding Models Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expected-performance-results-on-jetson-orin-nano" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Expected Performance Results on Jetson Orin Nano
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ† Model Recommendations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ† Model Recommendations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-real-time-applications-50ms-latency" class="md-nav__link">
    <span class="md-ellipsis">
      For Real-time Applications (&lt; 50ms latency):
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-high-quality-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      For High-Quality Embeddings:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-memory-constrained-environments" class="md-nav__link">
    <span class="md-ellipsis">
      For Memory-Constrained Environments:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-multilingual-applications" class="md-nav__link">
    <span class="md-ellipsis">
      For Multilingual Applications:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-database-evaluation-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ—„ï¸ Vector Database Evaluation on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ—„ï¸ Vector Database Evaluation on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vector-database-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Vector Database Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¬ Vector Database Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expected-vector-database-performance-on-jetson-orin-nano" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Expected Vector Database Performance on Jetson Orin Nano
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ† Vector Database Recommendations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ† Vector Database Recommendations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#faiss-best-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ FAISS - Best for Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chromadb-best-for-ease-of-use" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ ChromaDB - Best for Ease of Use
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qdrant-best-for-production" class="md-nav__link">
    <span class="md-ellipsis">
      âš™ï¸ Qdrant - Best for Production
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nvidia-cuvs-gpu-accelerated-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ NVIDIA cuVS: GPU-Accelerated Vector Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸš€ NVIDIA cuVS: GPU-Accelerated Vector Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-to-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¯ Introduction to cuVS
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¯ Introduction to cuVS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ Key Features:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuvs-installation-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“¦ cuVS Installation on Jetson
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuvs-performance-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§ª cuVS Performance Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expected-cuvs-performance-on-jetson-orin" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Expected cuVS Performance on Jetson Orin
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding-optimization-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ Embedding Optimization Strategies
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”§ Embedding Optimization Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-model-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      1. Model Quantization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-tensorrt-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      2. TensorRT Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-batch-processing-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      3. Batch Processing Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#integration-with-langchain" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¯ Integration with LangChain
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-summary" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ† Performance Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-build-rag-app-with-multiple-backends-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§ª Lab: Build RAG App with Multiple Backends on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ§ª Lab: Build RAG App with Multiple Backends on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§° Setup
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-load-and-split-document" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¹ Step 1: Load and Split Document
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-embed-and-index-choose-backend" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¹ Step 2: Embed and Index (Choose Backend)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”¹ Step 2: Embed and Index (Choose Backend)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#option-a-chromadb" class="md-nav__link">
    <span class="md-ellipsis">
      Option A: ChromaDB
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#option-b-faiss" class="md-nav__link">
    <span class="md-ellipsis">
      Option B: FAISS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#option-c-qdrant-self-hosted-or-remote" class="md-nav__link">
    <span class="md-ellipsis">
      Option C: Qdrant (self-hosted or remote)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-rag-with-multiple-model-inference-backends" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¹ Step 3: RAG with Multiple Model Inference Backends
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”¹ Step 3: RAG with Multiple Model Inference Backends">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama-cpp-backend-local-gguf-model" class="md-nav__link">
    <span class="md-ellipsis">
      âœ… llama-cpp Backend (Local GGUF Model)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ollama-backend-local-rest-api" class="md-nav__link">
    <span class="md-ellipsis">
      âœ… Ollama Backend (Local REST API)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-deliverables" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“‹ Lab Deliverables
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#use-cases-for-jetson-edge" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ’¡ Use Cases for Jetson Edge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      âœ… Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-rag" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¤” What is RAG?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¤” What is RAG?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-technology-behind-rag" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¬ The Technology Behind RAG
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”¬ The Technology Behind RAG">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-components" class="md-nav__link">
    <span class="md-ellipsis">
      Core Components:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rag-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      RAG Workflow:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§  Understanding Embeddings
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ§  Understanding Embeddings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-properties" class="md-nav__link">
    <span class="md-ellipsis">
      Key Properties:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-embedding-models" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Embedding Models:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-rag-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ’¡ Why RAG on Jetson?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ’¡ Why RAG on Jetson?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-ai-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      Edge AI Advantages:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jetson-specific-benefits" class="md-nav__link">
    <span class="md-ellipsis">
      Jetson-Specific Benefits:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-rag-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ Advanced RAG Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”§ Advanced RAG Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rag-pipeline-components" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š RAG Pipeline Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detailed-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ—ï¸ Detailed Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rag-optimization-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¯ RAG Optimization Strategies
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¯ RAG Optimization Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chunking-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Chunking Strategies:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retrieval-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval Strategies:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-enhancement" class="md-nav__link">
    <span class="md-ellipsis">
      Context Enhancement:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-components-in-langchain" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§± Key Components in LangChain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#embedding-models-evaluation-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ Embedding Models Evaluation on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸš€ Embedding Models Evaluation on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embedding-model-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“‹ Embedding Model Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding-models-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¬ Embedding Models Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expected-performance-results-on-jetson-orin-nano" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Expected Performance Results on Jetson Orin Nano
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ† Model Recommendations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ† Model Recommendations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-real-time-applications-50ms-latency" class="md-nav__link">
    <span class="md-ellipsis">
      For Real-time Applications (&lt; 50ms latency):
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-high-quality-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      For High-Quality Embeddings:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-memory-constrained-environments" class="md-nav__link">
    <span class="md-ellipsis">
      For Memory-Constrained Environments:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-multilingual-applications" class="md-nav__link">
    <span class="md-ellipsis">
      For Multilingual Applications:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-database-evaluation-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ—„ï¸ Vector Database Evaluation on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ—„ï¸ Vector Database Evaluation on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vector-database-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Vector Database Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¬ Vector Database Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expected-vector-database-performance-on-jetson-orin-nano" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Expected Vector Database Performance on Jetson Orin Nano
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ† Vector Database Recommendations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ† Vector Database Recommendations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#faiss-best-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ FAISS - Best for Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chromadb-best-for-ease-of-use" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ ChromaDB - Best for Ease of Use
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qdrant-best-for-production" class="md-nav__link">
    <span class="md-ellipsis">
      âš™ï¸ Qdrant - Best for Production
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nvidia-cuvs-gpu-accelerated-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ NVIDIA cuVS: GPU-Accelerated Vector Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸš€ NVIDIA cuVS: GPU-Accelerated Vector Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-to-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¯ Introduction to cuVS
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¯ Introduction to cuVS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ Key Features:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuvs-installation-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“¦ cuVS Installation on Jetson
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuvs-performance-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§ª cuVS Performance Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expected-cuvs-performance-on-jetson-orin" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“Š Expected cuVS Performance on Jetson Orin
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding-optimization-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”§ Embedding Optimization Strategies
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”§ Embedding Optimization Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-model-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      1. Model Quantization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-tensorrt-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      2. TensorRT Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-batch-processing-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      3. Batch Processing Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#integration-with-langchain" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ¯ Integration with LangChain
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-summary" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ† Performance Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-build-rag-app-with-multiple-backends-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§ª Lab: Build RAG App with Multiple Backends on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ§ª Lab: Build RAG App with Multiple Backends on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§° Setup
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-load-and-split-document" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¹ Step 1: Load and Split Document
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-embed-and-index-choose-backend" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¹ Step 2: Embed and Index (Choose Backend)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”¹ Step 2: Embed and Index (Choose Backend)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#option-a-chromadb" class="md-nav__link">
    <span class="md-ellipsis">
      Option A: ChromaDB
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#option-b-faiss" class="md-nav__link">
    <span class="md-ellipsis">
      Option B: FAISS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#option-c-qdrant-self-hosted-or-remote" class="md-nav__link">
    <span class="md-ellipsis">
      Option C: Qdrant (self-hosted or remote)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-rag-with-multiple-model-inference-backends" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”¹ Step 3: RAG with Multiple Model Inference Backends
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”¹ Step 3: RAG with Multiple Model Inference Backends">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama-cpp-backend-local-gguf-model" class="md-nav__link">
    <span class="md-ellipsis">
      âœ… llama-cpp Backend (Local GGUF Model)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ollama-backend-local-rest-api" class="md-nav__link">
    <span class="md-ellipsis">
      âœ… Ollama Backend (Local REST API)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-deliverables" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ“‹ Lab Deliverables
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#use-cases-for-jetson-edge" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ’¡ Use Cases for Jetson Edge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      âœ… Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="rag-applications-with-langchain-on-jetson">ğŸ“š RAG Applications with LangChain on Jetson<a class="headerlink" href="#rag-applications-with-langchain-on-jetson" title="Permanent link">&para;</a></h1>
<p><strong>Author:</strong> Dr. Kaikai Liu, Ph.D.<br />
<strong>Position:</strong> Associate Professor, Computer Engineering<br />
<strong>Institution:</strong> San Jose State University<br />
<strong>Contact:</strong> <a href="mailto:kaikai.liu@sjsu.edu">kaikai.liu@sjsu.edu</a></p>
<h2 id="what-is-rag">ğŸ¤” What is RAG?<a class="headerlink" href="#what-is-rag" title="Permanent link">&para;</a></h2>
<p><strong>RAG (Retrieval-Augmented Generation)</strong> is a powerful paradigm that combines the generative capabilities of Large Language Models (LLMs) with external knowledge retrieval. Unlike traditional LLMs that rely solely on their pre-trained parameters, RAG systems dynamically retrieve relevant information from external knowledge bases to augment the generation process.</p>
<h3 id="the-technology-behind-rag">ğŸ”¬ The Technology Behind RAG<a class="headerlink" href="#the-technology-behind-rag" title="Permanent link">&para;</a></h3>
<h4 id="core-components"><strong>Core Components:</strong><a class="headerlink" href="#core-components" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Knowledge Base</strong>: External documents, databases, or structured data</li>
<li><strong>Embedding Model</strong>: Converts text into high-dimensional vector representations</li>
<li><strong>Vector Database</strong>: Stores and indexes embeddings for efficient similarity search</li>
<li><strong>Retriever</strong>: Finds relevant documents based on query similarity</li>
<li><strong>Generator</strong>: LLM that produces responses using retrieved context</li>
</ol>
<h4 id="rag-workflow"><strong>RAG Workflow:</strong><a class="headerlink" href="#rag-workflow" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>User Query â†’ Embedding â†’ Vector Search â†’ Context Retrieval â†’ LLM Generation â†’ Response
</code></pre></div>
<h3 id="understanding-embeddings">ğŸ§  Understanding Embeddings<a class="headerlink" href="#understanding-embeddings" title="Permanent link">&para;</a></h3>
<p><strong>Embeddings</strong> are dense vector representations that capture semantic meaning of text. They enable machines to understand that "car" and "automobile" are semantically similar, even though they share no common characters.</p>
<h4 id="key-properties"><strong>Key Properties:</strong><a class="headerlink" href="#key-properties" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Dimensionality</strong>: Typically 384-1536 dimensions</li>
<li><strong>Semantic Similarity</strong>: Similar concepts have similar vectors</li>
<li><strong>Distance Metrics</strong>: Cosine similarity, Euclidean distance, dot product</li>
<li><strong>Context Awareness</strong>: Modern embeddings capture contextual meaning</li>
</ul>
<h4 id="types-of-embedding-models"><strong>Types of Embedding Models:</strong><a class="headerlink" href="#types-of-embedding-models" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Sentence Transformers</strong>: Optimized for semantic similarity</li>
<li><strong>OpenAI Embeddings</strong>: High-quality but require API calls</li>
<li><strong>Local Models</strong>: BERT, RoBERTa, E5, BGE variants</li>
<li><strong>Multilingual Models</strong>: Support multiple languages</li>
<li><strong>Domain-Specific</strong>: Fine-tuned for specific domains (legal, medical, code)</li>
</ol>
<h3 id="why-rag-on-jetson">ğŸ’¡ Why RAG on Jetson?<a class="headerlink" href="#why-rag-on-jetson" title="Permanent link">&para;</a></h3>
<h4 id="edge-ai-advantages"><strong>Edge AI Advantages:</strong><a class="headerlink" href="#edge-ai-advantages" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Privacy</strong>: Keep sensitive data local, no cloud dependency</li>
<li><strong>Latency</strong>: Sub-second response times for real-time applications</li>
<li><strong>Reliability</strong>: Works offline, immune to network issues</li>
<li><strong>Cost</strong>: No API costs for embeddings and inference</li>
<li><strong>Customization</strong>: Fine-tune models for specific use cases</li>
</ul>
<h4 id="jetson-specific-benefits"><strong>Jetson-Specific Benefits:</strong><a class="headerlink" href="#jetson-specific-benefits" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>GPU Acceleration</strong>: CUDA support for embedding computation</li>
<li><strong>Memory Efficiency</strong>: Optimized models for edge deployment</li>
<li><strong>Power Efficiency</strong>: Low-power consumption for continuous operation</li>
<li><strong>Integration</strong>: Easy integration with sensors and IoT devices</li>
</ul>
<hr />
<h2 id="advanced-rag-architecture">ğŸ”§ Advanced RAG Architecture<a class="headerlink" href="#advanced-rag-architecture" title="Permanent link">&para;</a></h2>
<h3 id="rag-pipeline-components">ğŸ“Š RAG Pipeline Components<a class="headerlink" href="#rag-pipeline-components" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>graph TD
    A[User Query] --&gt; B[Query Embedding]
    B --&gt; C[Vector Search]
    C --&gt; D[Document Retrieval]
    D --&gt; E[Context Ranking]
    E --&gt; F[Prompt Construction]
    F --&gt; G[LLM Generation]
    G --&gt; H[Response]

    I[Document Corpus] --&gt; J[Text Chunking]
    J --&gt; K[Embedding Generation]
    K --&gt; L[Vector Storage]
    L --&gt; C
</code></pre></div>
<h3 id="detailed-architecture">ğŸ—ï¸ Detailed Architecture<a class="headerlink" href="#detailed-architecture" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Indexing Phase</strong> (Offline):</li>
<li>Document loading and preprocessing</li>
<li>Text chunking with overlap strategies</li>
<li>Embedding generation using optimized models</li>
<li>
<p>Vector storage with efficient indexing</p>
</li>
<li>
<p><strong>Retrieval Phase</strong> (Online):</p>
</li>
<li>Query embedding generation</li>
<li>Similarity search in vector space</li>
<li>Context ranking and filtering</li>
<li>
<p>Prompt template construction</p>
</li>
<li>
<p><strong>Generation Phase</strong>:</p>
</li>
<li>Context-aware LLM inference</li>
<li>Response generation and post-processing</li>
<li>Optional fact-checking and validation</li>
</ol>
<h3 id="rag-optimization-strategies">ğŸ¯ RAG Optimization Strategies<a class="headerlink" href="#rag-optimization-strategies" title="Permanent link">&para;</a></h3>
<h4 id="chunking-strategies"><strong>Chunking Strategies:</strong><a class="headerlink" href="#chunking-strategies" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Fixed-size</strong>: Simple but may break semantic units</li>
<li><strong>Semantic</strong>: Preserve paragraph/sentence boundaries</li>
<li><strong>Recursive</strong>: Hierarchical chunking with multiple levels</li>
<li><strong>Sliding window</strong>: Overlapping chunks for context preservation</li>
</ul>
<h4 id="retrieval-strategies"><strong>Retrieval Strategies:</strong><a class="headerlink" href="#retrieval-strategies" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Dense Retrieval</strong>: Vector similarity search</li>
<li><strong>Sparse Retrieval</strong>: BM25, TF-IDF keyword matching</li>
<li><strong>Hybrid Retrieval</strong>: Combine dense and sparse methods</li>
<li><strong>Multi-vector</strong>: Multiple embeddings per document</li>
</ul>
<h4 id="context-enhancement"><strong>Context Enhancement:</strong><a class="headerlink" href="#context-enhancement" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Re-ranking</strong>: Secondary ranking of retrieved documents</li>
<li><strong>Query expansion</strong>: Enhance queries with related terms</li>
<li><strong>Context compression</strong>: Summarize long retrieved contexts</li>
<li><strong>Multi-hop</strong>: Iterative retrieval for complex queries</li>
</ul>
<hr />
<h2 id="key-components-in-langchain">ğŸ§± Key Components in LangChain<a class="headerlink" href="#key-components-in-langchain" title="Permanent link">&para;</a></h2>
<ul>
<li><code>DocumentLoader</code>: Load PDFs, markdowns, text, web pages</li>
<li><code>TextSplitter</code>: Break documents into chunks with various strategies</li>
<li><code>Embeddings</code>: Convert text to vectors using local or cloud models</li>
<li><code>VectorStore</code>: FAISS, Chroma, Qdrant, Weaviate, Pinecone</li>
<li><code>Retriever</code>: Pull relevant chunks with ranking and filtering</li>
<li><code>LLM</code>: Generate final answer using GGUF models via llama-cpp or Ollama</li>
</ul>
<hr />
<h2 id="embedding-models-evaluation-on-jetson">ğŸš€ Embedding Models Evaluation on Jetson<a class="headerlink" href="#embedding-models-evaluation-on-jetson" title="Permanent link">&para;</a></h2>
<h3 id="embedding-model-comparison">ğŸ“‹ Embedding Model Comparison<a class="headerlink" href="#embedding-model-comparison" title="Permanent link">&para;</a></h3>
<p>We'll evaluate various embedding models on Jetson platforms focusing on:
- <strong>Performance</strong>: Inference speed and throughput
- <strong>Quality</strong>: Semantic similarity accuracy
- <strong>Memory</strong>: RAM and VRAM usage
- <strong>Power</strong>: Energy consumption</p>
<h3 id="embedding-models-benchmark">ğŸ”¬ Embedding Models Benchmark<a class="headerlink" href="#embedding-models-benchmark" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>

<span class="k">class</span><span class="w"> </span><span class="nc">EmbeddingBenchmark</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive embedding model benchmark for Jetson&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># Lightweight models (&lt; 100MB)</span>
            <span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;all-MiniLM-L12-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/all-MiniLM-L12-v2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;paraphrase-MiniLM-L6-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/paraphrase-MiniLM-L6-v2&quot;</span><span class="p">,</span>

            <span class="c1"># Medium models (100-500MB)</span>
            <span class="s2">&quot;all-mpnet-base-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/all-mpnet-base-v2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;all-roberta-large-v1&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/all-roberta-large-v1&quot;</span><span class="p">,</span>
            <span class="s2">&quot;e5-base-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;intfloat/e5-base-v2&quot;</span><span class="p">,</span>

            <span class="c1"># Large models (&gt; 500MB)</span>
            <span class="s2">&quot;e5-large-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;intfloat/e5-large-v2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bge-large-en-v1.5&quot;</span><span class="p">:</span> <span class="s2">&quot;BAAI/bge-large-en-v1.5&quot;</span><span class="p">,</span>
            <span class="s2">&quot;gte-large&quot;</span><span class="p">:</span> <span class="s2">&quot;thenlper/gte-large&quot;</span><span class="p">,</span>

            <span class="c1"># Multilingual models</span>
            <span class="s2">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;multilingual-e5-base&quot;</span><span class="p">:</span> <span class="s2">&quot;intfloat/multilingual-e5-base&quot;</span>
        <span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test_texts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;NVIDIA Jetson is a series of embedded computing boards from NVIDIA.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;The Jetson platform provides AI computing at the edge with GPU acceleration.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Deep learning models can be optimized for inference on Jetson devices.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;TensorRT enables high-performance inference on NVIDIA GPUs.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Edge AI applications benefit from local processing capabilities.&quot;</span>
        <span class="p">]</span> <span class="o">*</span> <span class="mi">20</span>  <span class="c1"># 100 texts for throughput testing</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark a single embedding model&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ” Benchmarking </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Load model</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;sentence-transformers&quot;</span> <span class="ow">in</span> <span class="n">model_path</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use transformers directly for more control</span>
                <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

            <span class="n">load_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

            <span class="c1"># Memory usage before inference</span>
            <span class="n">process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">process</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># MB</span>

            <span class="c1"># GPU memory (if available)</span>
            <span class="n">gpu_memory_before</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
                <span class="n">gpu_memory_before</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># MB</span>

            <span class="c1"># Warm-up</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;encode&#39;</span><span class="p">):</span>
                <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="s2">&quot;warm up&quot;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For transformers models</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="s2">&quot;warm up&quot;</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Benchmark inference speed</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;encode&#39;</span><span class="p">):</span>
                <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_texts</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For transformers models - batch processing</span>
                <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_texts</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_texts</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                        <span class="c1"># Mean pooling</span>
                        <span class="n">batch_embeddings</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">embeddings</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">batch_embeddings</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

            <span class="n">inference_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

            <span class="c1"># Memory usage after inference</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">process</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># MB</span>
            <span class="n">gpu_memory_after</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">gpu_memory_after</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># MB</span>

            <span class="c1"># Calculate metrics</span>
            <span class="n">throughput</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_texts</span><span class="p">)</span> <span class="o">/</span> <span class="n">inference_time</span>  <span class="c1"># texts per second</span>
            <span class="n">avg_latency</span> <span class="o">=</span> <span class="n">inference_time</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_texts</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms per text</span>

            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
                <span class="s2">&quot;load_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">load_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;inference_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">inference_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;throughput_texts_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">throughput</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;avg_latency_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_latency</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;gpu_memory_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">gpu_memory_after</span> <span class="o">-</span> <span class="n">gpu_memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;embedding_dim&quot;</span><span class="p">:</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="s2">&quot;total_memory_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

            <span class="c1"># Clean up</span>
            <span class="k">del</span> <span class="n">model</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_full_benchmark</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run benchmark on all models&quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸš€ Starting Embedding Models Benchmark on Jetson&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;throughput_texts_per_sec&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> texts/sec, &quot;</span>
                      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;avg_latency_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">ms latency, &quot;</span>
                      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;memory_usage_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">MB memory&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âŒ </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate comprehensive benchmark report&quot;&quot;&quot;</span>
        <span class="n">successful_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">successful_results</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;No successful benchmarks to report.&quot;</span>

        <span class="c1"># Sort by throughput</span>
        <span class="n">successful_results</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;throughput_texts_per_sec&quot;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">report</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ† JETSON EMBEDDING MODELS BENCHMARK REPORT</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Performance ranking</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ“Š PERFORMANCE RANKING (by throughput):</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">successful_results</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;throughput_texts_per_sec&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8.1f</span><span class="si">}</span><span class="s2"> texts/sec</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Memory efficiency ranking</span>
        <span class="n">memory_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">])</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ’¾ MEMORY EFFICIENCY RANKING:</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">memory_sorted</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;memory_usage_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8.1f</span><span class="si">}</span><span class="s2"> MB</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Latency ranking</span>
        <span class="n">latency_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;avg_latency_ms&quot;</span><span class="p">])</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">âš¡ LATENCY RANKING (lower is better):</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">latency_sorted</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;avg_latency_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8.1f</span><span class="si">}</span><span class="s2"> ms</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Recommendations</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ¯ RECOMMENDATIONS FOR JETSON:</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">fastest</span> <span class="o">=</span> <span class="n">successful_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">most_efficient</span> <span class="o">=</span> <span class="n">memory_sorted</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">lowest_latency</span> <span class="o">=</span> <span class="n">latency_sorted</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸš€ Best Performance: </span><span class="si">{</span><span class="n">fastest</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸ’¾ Most Memory Efficient: </span><span class="si">{</span><span class="n">most_efficient</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;âš¡ Lowest Latency: </span><span class="si">{</span><span class="n">lowest_latency</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Use case recommendations</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ“‹ USE CASE RECOMMENDATIONS:</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Real-time applications: Use models with &lt;50ms latency</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Batch processing: Use highest throughput models</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Memory-constrained: Use models with &lt;200MB memory usage</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Production deployment: Balance performance and memory efficiency</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">report</span>

<span class="c1"># Run the benchmark</span>
<span class="n">benchmark</span> <span class="o">=</span> <span class="n">EmbeddingBenchmark</span><span class="p">()</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">run_full_benchmark</span><span class="p">()</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">generate_report</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</code></pre></div>
<h3 id="expected-performance-results-on-jetson-orin-nano">ğŸ“Š Expected Performance Results on Jetson Orin Nano<a class="headerlink" href="#expected-performance-results-on-jetson-orin-nano" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Throughput (texts/sec)</th>
<th>Latency (ms)</th>
<th>Memory (MB)</th>
<th>Embedding Dim</th>
</tr>
</thead>
<tbody>
<tr>
<td>all-MiniLM-L6-v2</td>
<td>45.2</td>
<td>22.1</td>
<td>90</td>
<td>384</td>
</tr>
<tr>
<td>paraphrase-MiniLM-L6-v2</td>
<td>43.8</td>
<td>22.8</td>
<td>90</td>
<td>384</td>
</tr>
<tr>
<td>all-MiniLM-L12-v2</td>
<td>28.5</td>
<td>35.1</td>
<td>134</td>
<td>384</td>
</tr>
<tr>
<td>e5-base-v2</td>
<td>22.1</td>
<td>45.2</td>
<td>438</td>
<td>768</td>
</tr>
<tr>
<td>all-mpnet-base-v2</td>
<td>18.7</td>
<td>53.5</td>
<td>438</td>
<td>768</td>
</tr>
<tr>
<td>bge-large-en-v1.5</td>
<td>8.9</td>
<td>112.4</td>
<td>1340</td>
<td>1024</td>
</tr>
</tbody>
</table>
<h3 id="model-recommendations">ğŸ† Model Recommendations<a class="headerlink" href="#model-recommendations" title="Permanent link">&para;</a></h3>
<h4 id="for-real-time-applications-50ms-latency"><strong>For Real-time Applications (&lt; 50ms latency):</strong><a class="headerlink" href="#for-real-time-applications-50ms-latency" title="Permanent link">&para;</a></h4>
<ul>
<li>âœ… <code>all-MiniLM-L6-v2</code>: Best balance of speed and quality</li>
<li>âœ… <code>paraphrase-MiniLM-L6-v2</code>: Good for paraphrase detection</li>
<li>âœ… <code>all-MiniLM-L12-v2</code>: Slightly better quality, acceptable latency</li>
</ul>
<h4 id="for-high-quality-embeddings"><strong>For High-Quality Embeddings:</strong><a class="headerlink" href="#for-high-quality-embeddings" title="Permanent link">&para;</a></h4>
<ul>
<li>âœ… <code>e5-base-v2</code>: Excellent quality-performance balance</li>
<li>âœ… <code>all-mpnet-base-v2</code>: Strong semantic understanding</li>
<li>âš ï¸ <code>bge-large-en-v1.5</code>: Best quality but slower</li>
</ul>
<h4 id="for-memory-constrained-environments"><strong>For Memory-Constrained Environments:</strong><a class="headerlink" href="#for-memory-constrained-environments" title="Permanent link">&para;</a></h4>
<ul>
<li>âœ… <code>all-MiniLM-L6-v2</code>: Only 90MB memory usage</li>
<li>âœ… <code>paraphrase-MiniLM-L6-v2</code>: Lightweight and efficient</li>
</ul>
<h4 id="for-multilingual-applications"><strong>For Multilingual Applications:</strong><a class="headerlink" href="#for-multilingual-applications" title="Permanent link">&para;</a></h4>
<ul>
<li>âœ… <code>paraphrase-multilingual-MiniLM-L12-v2</code>: Good multilingual support</li>
<li>âœ… <code>multilingual-e5-base</code>: Better quality for non-English</li>
</ul>
<hr />
<h2 id="vector-database-evaluation-on-jetson">ğŸ—„ï¸ Vector Database Evaluation on Jetson<a class="headerlink" href="#vector-database-evaluation-on-jetson" title="Permanent link">&para;</a></h2>
<h3 id="vector-database-comparison">ğŸ“Š Vector Database Comparison<a class="headerlink" href="#vector-database-comparison" title="Permanent link">&para;</a></h3>
<p>We'll evaluate different vector databases for Jetson deployment focusing on:
- <strong>Performance</strong>: Query speed and indexing time
- <strong>Memory Efficiency</strong>: RAM usage and storage requirements
- <strong>Scalability</strong>: Handling large document collections
- <strong>Features</strong>: Filtering, metadata support, persistence</p>
<h3 id="vector-database-benchmark">ğŸ”¬ Vector Database Benchmark<a class="headerlink" href="#vector-database-benchmark" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Vector database imports</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">chromadb</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">chromadb.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">Settings</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">chromadb</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">faiss</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">faiss</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">qdrant_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">QdrantClient</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">qdrant_client.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Distance</span><span class="p">,</span> <span class="n">VectorParams</span><span class="p">,</span> <span class="n">PointStruct</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">QdrantClient</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">weaviate</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">weaviate</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">class</span><span class="w"> </span><span class="nc">VectorDBBenchmark</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive vector database benchmark for Jetson&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">embedding_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">384</span>  <span class="c1"># for all-MiniLM-L6-v2</span>

        <span class="c1"># Generate test data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_test_documents</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_embeddings</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_texts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;What is NVIDIA Jetson used for?&quot;</span><span class="p">,</span>
            <span class="s2">&quot;How to optimize deep learning models?&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Edge AI computing benefits&quot;</span><span class="p">,</span>
            <span class="s2">&quot;TensorRT optimization techniques&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Real-time inference on embedded devices&quot;</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_texts</span><span class="p">)</span>

        <span class="c1"># Test configurations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">]</span>  <span class="c1"># Number of documents</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_test_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate synthetic test documents&quot;&quot;&quot;</span>
        <span class="n">base_texts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;NVIDIA Jetson is a series of embedded computing boards designed for AI applications.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Deep learning models can be optimized using TensorRT for faster inference.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Edge AI enables real-time processing without cloud connectivity.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Computer vision applications benefit from GPU acceleration on Jetson.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Natural language processing models can run locally on edge devices.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Autonomous vehicles use edge computing for real-time decision making.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;IoT devices with AI capabilities enable smart city applications.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Robotics applications leverage edge AI for autonomous navigation.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Industrial automation uses AI for predictive maintenance.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Healthcare devices benefit from local AI processing for privacy.&quot;</span>
        <span class="p">]</span>

        <span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>  <span class="c1"># Generate 5000 documents</span>
            <span class="n">base_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">base_texts</span><span class="p">)</span>
            <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_texts</span><span class="p">[</span><span class="n">base_idx</span><span class="p">]</span><span class="si">}</span><span class="s2"> Document </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> with additional context and variations.&quot;</span>
            <span class="n">documents</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;doc_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
                <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;category&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;AI&quot;</span><span class="p">,</span> <span class="s2">&quot;Edge Computing&quot;</span><span class="p">,</span> <span class="s2">&quot;Jetson&quot;</span><span class="p">,</span> <span class="s2">&quot;Deep Learning&quot;</span><span class="p">][</span><span class="n">i</span> <span class="o">%</span> <span class="mi">4</span><span class="p">],</span>
                    <span class="s2">&quot;priority&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">3</span><span class="p">,</span>
                    <span class="s2">&quot;timestamp&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;2024-01-</span><span class="si">{</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">30</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">}</span>
            <span class="p">})</span>

        <span class="k">return</span> <span class="n">documents</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate embeddings for test documents&quot;&quot;&quot;</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_chromadb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark ChromaDB&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">chromadb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="s2">&quot;ChromaDB not installed&quot;</span><span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Setup</span>
            <span class="n">db_path</span> <span class="o">=</span> <span class="s2">&quot;./benchmark_chroma&quot;</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">db_path</span><span class="p">):</span>
                <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>

            <span class="n">client</span> <span class="o">=</span> <span class="n">chromadb</span><span class="o">.</span><span class="n">PersistentClient</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">db_path</span><span class="p">)</span>
            <span class="n">collection</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">create_collection</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;benchmark&quot;</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;hnsw:space&quot;</span><span class="p">:</span> <span class="s2">&quot;cosine&quot;</span><span class="p">}</span>
            <span class="p">)</span>

            <span class="c1"># Indexing benchmark</span>
            <span class="n">docs_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span>
            <span class="n">embeddings_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span>

            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Add documents in batches</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">batch_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">)</span>
                <span class="n">batch_docs</span> <span class="o">=</span> <span class="n">docs_subset</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">batch_end</span><span class="p">]</span>
                <span class="n">batch_embeddings</span> <span class="o">=</span> <span class="n">embeddings_subset</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">batch_end</span><span class="p">]</span>

                <span class="n">collection</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                    <span class="n">embeddings</span><span class="o">=</span><span class="n">batch_embeddings</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                    <span class="n">documents</span><span class="o">=</span><span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">batch_docs</span><span class="p">],</span>
                    <span class="n">metadatas</span><span class="o">=</span><span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;metadata&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">batch_docs</span><span class="p">],</span>
                    <span class="n">ids</span><span class="o">=</span><span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">batch_docs</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="n">indexing_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Query benchmark</span>
            <span class="n">query_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">query_embedding</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="p">:</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">results</span> <span class="o">=</span> <span class="n">collection</span><span class="o">.</span><span class="n">query</span><span class="p">(</span>
                    <span class="n">query_embeddings</span><span class="o">=</span><span class="p">[</span><span class="n">query_embedding</span><span class="o">.</span><span class="n">tolist</span><span class="p">()],</span>
                    <span class="n">n_results</span><span class="o">=</span><span class="mi">5</span>
                <span class="p">)</span>
                <span class="n">query_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

            <span class="n">avg_query_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">query_times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>

            <span class="c1"># Storage size</span>
            <span class="n">storage_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">db_path</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span> 
                             <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">db_path</span><span class="p">,</span> <span class="n">f</span><span class="p">)))</span>
            <span class="n">storage_size_mb</span> <span class="o">=</span> <span class="n">storage_size</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Cleanup</span>
            <span class="n">client</span><span class="o">.</span><span class="n">delete_collection</span><span class="p">(</span><span class="s2">&quot;benchmark&quot;</span><span class="p">)</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;database&quot;</span><span class="p">:</span> <span class="s2">&quot;ChromaDB&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_docs&quot;</span><span class="p">:</span> <span class="n">num_docs</span><span class="p">,</span>
                <span class="s2">&quot;indexing_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">indexing_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_query_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;storage_size_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">storage_size_mb</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;throughput_docs_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">num_docs</span> <span class="o">/</span> <span class="n">indexing_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;database&quot;</span><span class="p">:</span> <span class="s2">&quot;ChromaDB&quot;</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_faiss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark FAISS&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">faiss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="s2">&quot;FAISS not installed&quot;</span><span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Setup FAISS index</span>
            <span class="n">embeddings_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Create and train index</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatIP</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">)</span>  <span class="c1"># Inner product (cosine similarity)</span>
            <span class="n">index</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embeddings_subset</span><span class="p">)</span>

            <span class="n">indexing_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Query benchmark</span>
            <span class="n">query_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">query_embedding</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="p">:</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">query_vector</span> <span class="o">=</span> <span class="n">query_embedding</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query_vector</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
                <span class="n">query_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

            <span class="n">avg_query_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">query_times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>

            <span class="c1"># Estimate storage size (in-memory)</span>
            <span class="n">storage_size_mb</span> <span class="o">=</span> <span class="n">embeddings_subset</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;database&quot;</span><span class="p">:</span> <span class="s2">&quot;FAISS&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_docs&quot;</span><span class="p">:</span> <span class="n">num_docs</span><span class="p">,</span>
                <span class="s2">&quot;indexing_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">indexing_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_query_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;storage_size_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">storage_size_mb</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;throughput_docs_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">num_docs</span> <span class="o">/</span> <span class="n">indexing_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;database&quot;</span><span class="p">:</span> <span class="s2">&quot;FAISS&quot;</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_qdrant</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark Qdrant&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">QdrantClient</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="s2">&quot;Qdrant not installed&quot;</span><span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Setup</span>
            <span class="n">db_path</span> <span class="o">=</span> <span class="s2">&quot;./benchmark_qdrant&quot;</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">db_path</span><span class="p">):</span>
                <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>

            <span class="n">client</span> <span class="o">=</span> <span class="n">QdrantClient</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">db_path</span><span class="p">)</span>
            <span class="n">collection_name</span> <span class="o">=</span> <span class="s2">&quot;benchmark&quot;</span>

            <span class="c1"># Create collection</span>
            <span class="n">client</span><span class="o">.</span><span class="n">create_collection</span><span class="p">(</span>
                <span class="n">collection_name</span><span class="o">=</span><span class="n">collection_name</span><span class="p">,</span>
                <span class="n">vectors_config</span><span class="o">=</span><span class="n">VectorParams</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="n">Distance</span><span class="o">.</span><span class="n">COSINE</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Indexing benchmark</span>
            <span class="n">docs_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span>
            <span class="n">embeddings_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span>

            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Add documents in batches</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">batch_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">)</span>
                <span class="n">batch_docs</span> <span class="o">=</span> <span class="n">docs_subset</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">batch_end</span><span class="p">]</span>
                <span class="n">batch_embeddings</span> <span class="o">=</span> <span class="n">embeddings_subset</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">batch_end</span><span class="p">]</span>

                <span class="n">points</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">PointStruct</span><span class="p">(</span>
                        <span class="nb">id</span><span class="o">=</span><span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span>
                        <span class="n">vector</span><span class="o">=</span><span class="n">embedding</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                        <span class="n">payload</span><span class="o">=</span><span class="p">{</span>
                            <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">doc</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
                            <span class="o">**</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;metadata&quot;</span><span class="p">]</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">batch_docs</span><span class="p">,</span> <span class="n">batch_embeddings</span><span class="p">))</span>
                <span class="p">]</span>

                <span class="n">client</span><span class="o">.</span><span class="n">upsert</span><span class="p">(</span>
                    <span class="n">collection_name</span><span class="o">=</span><span class="n">collection_name</span><span class="p">,</span>
                    <span class="n">points</span><span class="o">=</span><span class="n">points</span>
                <span class="p">)</span>

            <span class="n">indexing_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Query benchmark</span>
            <span class="n">query_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">query_embedding</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="p">:</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">results</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                    <span class="n">collection_name</span><span class="o">=</span><span class="n">collection_name</span><span class="p">,</span>
                    <span class="n">query_vector</span><span class="o">=</span><span class="n">query_embedding</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                    <span class="n">limit</span><span class="o">=</span><span class="mi">5</span>
                <span class="p">)</span>
                <span class="n">query_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

            <span class="n">avg_query_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">query_times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>

            <span class="c1"># Storage size</span>
            <span class="n">storage_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">file</span><span class="p">))</span>
                             <span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>
                             <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">)</span>
            <span class="n">storage_size_mb</span> <span class="o">=</span> <span class="n">storage_size</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Cleanup</span>
            <span class="n">client</span><span class="o">.</span><span class="n">delete_collection</span><span class="p">(</span><span class="n">collection_name</span><span class="p">)</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;database&quot;</span><span class="p">:</span> <span class="s2">&quot;Qdrant&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_docs&quot;</span><span class="p">:</span> <span class="n">num_docs</span><span class="p">,</span>
                <span class="s2">&quot;indexing_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">indexing_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_query_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;storage_size_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">storage_size_mb</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;throughput_docs_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">num_docs</span> <span class="o">/</span> <span class="n">indexing_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;database&quot;</span><span class="p">:</span> <span class="s2">&quot;Qdrant&quot;</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_comprehensive_benchmark</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run comprehensive benchmark across all databases and sizes&quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">databases</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;ChromaDB&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_chromadb</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;FAISS&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_faiss</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;Qdrant&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_qdrant</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸš€ Starting Vector Database Benchmark on Jetson&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">db_name</span><span class="p">,</span> <span class="n">benchmark_func</span> <span class="ow">in</span> <span class="n">databases</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ“Š Benchmarking </span><span class="si">{</span><span class="n">db_name</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">num_docs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_sizes</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Testing with </span><span class="si">{</span><span class="n">num_docs</span><span class="si">}</span><span class="s2"> documents...&quot;</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark_func</span><span class="p">(</span><span class="n">num_docs</span><span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    âœ… Indexing: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;indexing_time_s&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s, &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;Query: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;avg_query_time_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms, &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;Memory: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;memory_usage_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">MB&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    âŒ Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_comparison_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate comprehensive comparison report&quot;&quot;&quot;</span>
        <span class="n">successful_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">successful_results</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;No successful benchmarks to report.&quot;</span>

        <span class="n">report</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ† JETSON VECTOR DATABASE BENCHMARK REPORT</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Performance comparison by database</span>
        <span class="n">databases</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;database&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">successful_results</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">db</span> <span class="ow">in</span> <span class="n">databases</span><span class="p">:</span>
            <span class="n">db_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">successful_results</span> <span class="k">if</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;database&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">db</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">db_results</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ“Š </span><span class="si">{</span><span class="n">db</span><span class="si">}</span><span class="s2"> PERFORMANCE:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Docs&#39;</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Index(s)&#39;</span><span class="si">:</span><span class="s2">&lt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Query(ms)&#39;</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Memory(MB)&#39;</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Storage(MB)&#39;</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">db_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;num_docs&quot;</span><span class="p">]):</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;num_docs&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;indexing_time_s&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;10.2f</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;avg_query_time_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;12.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;memory_usage_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;12.1f</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;storage_size_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;12.1f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Best performers analysis</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ… BEST PERFORMERS:</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Fastest indexing</span>
        <span class="n">fastest_indexing</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;indexing_time_s&quot;</span><span class="p">])</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸš€ Fastest Indexing: </span><span class="si">{</span><span class="n">fastest_indexing</span><span class="p">[</span><span class="s1">&#39;database&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">fastest_indexing</span><span class="p">[</span><span class="s1">&#39;indexing_time_s&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s for </span><span class="si">{</span><span class="n">fastest_indexing</span><span class="p">[</span><span class="s1">&#39;num_docs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> docs)</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Fastest query</span>
        <span class="n">fastest_query</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">])</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;âš¡ Fastest Query: </span><span class="si">{</span><span class="n">fastest_query</span><span class="p">[</span><span class="s1">&#39;database&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">fastest_query</span><span class="p">[</span><span class="s1">&#39;avg_query_time_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms)</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Most memory efficient</span>
        <span class="n">most_efficient</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">])</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸ’¾ Most Memory Efficient: </span><span class="si">{</span><span class="n">most_efficient</span><span class="p">[</span><span class="s1">&#39;database&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">most_efficient</span><span class="p">[</span><span class="s1">&#39;memory_usage_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">MB)</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Smallest storage</span>
        <span class="n">smallest_storage</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;storage_size_mb&quot;</span><span class="p">])</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸ’½ Smallest Storage: </span><span class="si">{</span><span class="n">smallest_storage</span><span class="p">[</span><span class="s1">&#39;database&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">smallest_storage</span><span class="p">[</span><span class="s1">&#39;storage_size_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">MB)</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Recommendations</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ¯ RECOMMENDATIONS FOR JETSON:</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Real-time applications: Choose fastest query database</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Large datasets: Consider indexing speed and storage efficiency</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Memory-constrained: Use most memory-efficient option</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Persistence needed: Avoid in-memory only solutions</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Complex filtering: Choose databases with rich metadata support</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">report</span>

<span class="c1"># Run the benchmark</span>
<span class="n">vector_benchmark</span> <span class="o">=</span> <span class="n">VectorDBBenchmark</span><span class="p">()</span>
<span class="n">vector_results</span> <span class="o">=</span> <span class="n">vector_benchmark</span><span class="o">.</span><span class="n">run_comprehensive_benchmark</span><span class="p">()</span>
<span class="n">vector_report</span> <span class="o">=</span> <span class="n">vector_benchmark</span><span class="o">.</span><span class="n">generate_comparison_report</span><span class="p">(</span><span class="n">vector_results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vector_report</span><span class="p">)</span>
</code></pre></div>
<h3 id="expected-vector-database-performance-on-jetson-orin-nano">ğŸ“Š Expected Vector Database Performance on Jetson Orin Nano<a class="headerlink" href="#expected-vector-database-performance-on-jetson-orin-nano" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Database</th>
<th>Docs</th>
<th>Indexing (s)</th>
<th>Query (ms)</th>
<th>Memory (MB)</th>
<th>Storage (MB)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>FAISS</strong></td>
<td>1000</td>
<td>0.12</td>
<td>0.8</td>
<td>15</td>
<td>1.5</td>
</tr>
<tr>
<td><strong>FAISS</strong></td>
<td>5000</td>
<td>0.58</td>
<td>1.2</td>
<td>75</td>
<td>7.3</td>
</tr>
<tr>
<td><strong>ChromaDB</strong></td>
<td>1000</td>
<td>2.3</td>
<td>12.5</td>
<td>45</td>
<td>8.2</td>
</tr>
<tr>
<td><strong>ChromaDB</strong></td>
<td>5000</td>
<td>11.8</td>
<td>15.2</td>
<td>180</td>
<td>38.5</td>
</tr>
<tr>
<td><strong>Qdrant</strong></td>
<td>1000</td>
<td>3.1</td>
<td>8.7</td>
<td>52</td>
<td>12.1</td>
</tr>
<tr>
<td><strong>Qdrant</strong></td>
<td>5000</td>
<td>15.2</td>
<td>11.3</td>
<td>220</td>
<td>58.3</td>
</tr>
</tbody>
</table>
<h3 id="vector-database-recommendations">ğŸ† Vector Database Recommendations<a class="headerlink" href="#vector-database-recommendations" title="Permanent link">&para;</a></h3>
<h4 id="faiss-best-for-performance"><strong>ğŸš€ FAISS - Best for Performance</strong><a class="headerlink" href="#faiss-best-for-performance" title="Permanent link">&para;</a></h4>
<p><strong>Pros:</strong>
- âœ… Fastest indexing and query performance
- âœ… Minimal memory footprint
- âœ… Excellent for large-scale similarity search
- âœ… GPU acceleration support</p>
<p><strong>Cons:</strong>
- âŒ No built-in persistence (requires manual saving)
- âŒ Limited metadata filtering capabilities
- âŒ No distributed features</p>
<p><strong>Best for:</strong> High-performance applications, real-time search, memory-constrained environments</p>
<h4 id="chromadb-best-for-ease-of-use"><strong>ğŸ”§ ChromaDB - Best for Ease of Use</strong><a class="headerlink" href="#chromadb-best-for-ease-of-use" title="Permanent link">&para;</a></h4>
<p><strong>Pros:</strong>
- âœ… Simple API and great developer experience
- âœ… Built-in persistence
- âœ… Good metadata filtering
- âœ… Active community and documentation</p>
<p><strong>Cons:</strong>
- âŒ Slower than FAISS for large datasets
- âŒ Higher memory usage
- âŒ Limited scalability options</p>
<p><strong>Best for:</strong> Prototyping, small to medium datasets, applications requiring persistence</p>
<h4 id="qdrant-best-for-production"><strong>âš™ï¸ Qdrant - Best for Production</strong><a class="headerlink" href="#qdrant-best-for-production" title="Permanent link">&para;</a></h4>
<p><strong>Pros:</strong>
- âœ… Rich filtering and metadata support
- âœ… Built-in persistence and backup
- âœ… RESTful API for remote access
- âœ… Horizontal scaling capabilities</p>
<p><strong>Cons:</strong>
- âŒ Higher resource usage
- âŒ More complex setup
- âŒ Slower for simple similarity search</p>
<p><strong>Best for:</strong> Production applications, complex filtering requirements, distributed deployments</p>
<hr />
<h2 id="nvidia-cuvs-gpu-accelerated-vector-search">ğŸš€ NVIDIA cuVS: GPU-Accelerated Vector Search<a class="headerlink" href="#nvidia-cuvs-gpu-accelerated-vector-search" title="Permanent link">&para;</a></h2>
<h3 id="introduction-to-cuvs">ğŸ¯ Introduction to cuVS<a class="headerlink" href="#introduction-to-cuvs" title="Permanent link">&para;</a></h3>
<p><strong>NVIDIA cuVS (CUDA Vector Search)</strong> is a GPU-accelerated library for high-performance vector similarity search, specifically optimized for NVIDIA GPUs including Jetson platforms. It provides significant speedups over CPU-based vector search solutions.</p>
<h4 id="key-features"><strong>ğŸ”§ Key Features:</strong><a class="headerlink" href="#key-features" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>GPU Acceleration</strong>: Leverages CUDA cores for parallel vector operations</li>
<li><strong>Multiple Algorithms</strong>: Supports FAISS, HNSWLIB, and custom GPU implementations</li>
<li><strong>Memory Optimization</strong>: Efficient GPU memory management for large datasets</li>
<li><strong>Jetson Optimization</strong>: Specifically tuned for edge AI workloads</li>
<li><strong>Integration</strong>: Works seamlessly with existing ML pipelines</li>
</ul>
<h3 id="cuvs-installation-on-jetson">ğŸ“¦ cuVS Installation on Jetson<a class="headerlink" href="#cuvs-installation-on-jetson" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Install cuVS for Jetson (requires CUDA 11.8+)</span>
<span class="c1"># Method 1: Using conda (recommended)</span>
conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>rapidsai<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>cuvs-cu11

<span class="c1"># Method 2: Using pip</span>
pip<span class="w"> </span>install<span class="w"> </span>cuvs-cu11

<span class="c1"># Method 3: Build from source (for latest features)</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/rapidsai/cuvs.git
<span class="nb">cd</span><span class="w"> </span>cuvs
./build.sh
</code></pre></div>
<h3 id="cuvs-performance-benchmark">ğŸ§ª cuVS Performance Benchmark<a class="headerlink" href="#cuvs-performance-benchmark" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">cuvs</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">cuvs</span><span class="w"> </span><span class="kn">import</span> <span class="n">neighbors</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">cuvs</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cuVS not available. Install with: pip install cuvs-cu11&quot;</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">cp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CuPy not available. Install with: pip install cupy&quot;</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CuVSBenchmark</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark cuVS performance on Jetson&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">embedding_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">384</span>

        <span class="c1"># Generate test data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_test_documents</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_embeddings</span><span class="p">()</span>

        <span class="c1"># Test queries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_texts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;NVIDIA Jetson AI computing&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Deep learning optimization&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Edge AI applications&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Real-time inference&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Computer vision processing&quot;</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_texts</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_test_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate test documents for benchmarking&quot;&quot;&quot;</span>
        <span class="n">base_texts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;NVIDIA Jetson enables edge AI computing with GPU acceleration.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Deep learning models benefit from TensorRT optimization on Jetson.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Computer vision applications run efficiently on Jetson platforms.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Edge AI reduces latency and improves privacy for IoT devices.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Real-time inference is crucial for autonomous systems.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;CUDA programming enables parallel processing on Jetson GPUs.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Machine learning at the edge transforms industrial automation.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Jetson Orin provides high-performance AI computing in compact form.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Neural networks can be optimized for embedded deployment.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Edge computing brings intelligence closer to data sources.&quot;</span>
        <span class="p">]</span>

        <span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>  <span class="c1"># Generate 10k documents</span>
            <span class="n">base_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">base_texts</span><span class="p">)</span>
            <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_texts</span><span class="p">[</span><span class="n">base_idx</span><span class="p">]</span><span class="si">}</span><span class="s2"> Document </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> with additional context.&quot;</span>
            <span class="n">documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">documents</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate embeddings for test documents&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">,</span> 
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
            <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_cuvs_ivf_flat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark cuVS IVF-Flat index&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cuvs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">cp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS or CuPy not available&quot;</span><span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Prepare data</span>
            <span class="n">embeddings_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

            <span class="c1"># Move data to GPU</span>
            <span class="n">gpu_embeddings</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">embeddings_subset</span><span class="p">)</span>

            <span class="c1"># Build index</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Create IVF-Flat index</span>
            <span class="n">n_lists</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">num_docs</span><span class="p">)),</span> <span class="mi">1024</span><span class="p">)</span>  <span class="c1"># Adaptive number of clusters</span>
            <span class="n">index_params</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_flat</span><span class="o">.</span><span class="n">IndexParams</span><span class="p">(</span>
                <span class="n">n_lists</span><span class="o">=</span><span class="n">n_lists</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
                <span class="n">add_data_on_build</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="n">index</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_flat</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">index_params</span><span class="p">,</span> <span class="n">gpu_embeddings</span><span class="p">)</span>

            <span class="n">indexing_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Query benchmark</span>
            <span class="n">query_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">gpu_queries</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

            <span class="n">search_params</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_flat</span><span class="o">.</span><span class="n">SearchParams</span><span class="p">(</span><span class="n">n_probes</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">n_lists</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="p">)):</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">gpu_queries</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Single query</span>
                <span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_flat</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                    <span class="n">search_params</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span>
                <span class="p">)</span>
                <span class="n">cp</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="o">.</span><span class="n">null</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>  <span class="c1"># Ensure GPU completion</span>
                <span class="n">query_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

            <span class="n">avg_query_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">query_times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>

            <span class="c1"># GPU memory usage</span>
            <span class="n">gpu_memory_mb</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">get_default_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">used_bytes</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS IVF-Flat&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_docs&quot;</span><span class="p">:</span> <span class="n">num_docs</span><span class="p">,</span>
                <span class="s2">&quot;indexing_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">indexing_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_query_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;gpu_memory_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">gpu_memory_mb</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;throughput_docs_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">num_docs</span> <span class="o">/</span> <span class="n">indexing_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;n_lists&quot;</span><span class="p">:</span> <span class="n">n_lists</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS IVF-Flat&quot;</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_cuvs_ivf_pq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark cuVS IVF-PQ index (memory optimized)&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cuvs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">cp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS or CuPy not available&quot;</span><span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Prepare data</span>
            <span class="n">embeddings_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">gpu_embeddings</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">embeddings_subset</span><span class="p">)</span>

            <span class="c1"># Build index</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Create IVF-PQ index (Product Quantization for memory efficiency)</span>
            <span class="n">n_lists</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">num_docs</span><span class="p">)),</span> <span class="mi">512</span><span class="p">)</span>
            <span class="n">pq_bits</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># 8-bit quantization</span>
            <span class="n">pq_dim</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>  <span class="c1"># PQ subspace dimension</span>

            <span class="n">index_params</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_pq</span><span class="o">.</span><span class="n">IndexParams</span><span class="p">(</span>
                <span class="n">n_lists</span><span class="o">=</span><span class="n">n_lists</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
                <span class="n">pq_bits</span><span class="o">=</span><span class="n">pq_bits</span><span class="p">,</span>
                <span class="n">pq_dim</span><span class="o">=</span><span class="n">pq_dim</span><span class="p">,</span>
                <span class="n">add_data_on_build</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="n">index</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_pq</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">index_params</span><span class="p">,</span> <span class="n">gpu_embeddings</span><span class="p">)</span>

            <span class="n">indexing_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Query benchmark</span>
            <span class="n">query_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">gpu_queries</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

            <span class="n">search_params</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_pq</span><span class="o">.</span><span class="n">SearchParams</span><span class="p">(</span>
                <span class="n">n_probes</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">n_lists</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
                <span class="n">lut_dtype</span><span class="o">=</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="p">)):</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">gpu_queries</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">ivf_pq</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                    <span class="n">search_params</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span>
                <span class="p">)</span>
                <span class="n">cp</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="o">.</span><span class="n">null</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
                <span class="n">query_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

            <span class="n">avg_query_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">query_times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>

            <span class="c1"># GPU memory usage</span>
            <span class="n">gpu_memory_mb</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">get_default_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">used_bytes</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS IVF-PQ&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_docs&quot;</span><span class="p">:</span> <span class="n">num_docs</span><span class="p">,</span>
                <span class="s2">&quot;indexing_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">indexing_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_query_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;gpu_memory_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">gpu_memory_mb</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;throughput_docs_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">num_docs</span> <span class="o">/</span> <span class="n">indexing_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;compression_ratio&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="mi">32</span> <span class="o">/</span> <span class="n">pq_bits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># Memory compression</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS IVF-PQ&quot;</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">benchmark_cuvs_cagra</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Benchmark cuVS CAGRA index (GPU-optimized graph)&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cuvs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">cp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS or CuPy not available&quot;</span><span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Prepare data</span>
            <span class="n">embeddings_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">num_docs</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">gpu_embeddings</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">embeddings_subset</span><span class="p">)</span>

            <span class="c1"># Build index</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">memory_before</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Create CAGRA index (GPU-optimized graph-based)</span>
            <span class="n">index_params</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">cagra</span><span class="o">.</span><span class="n">IndexParams</span><span class="p">(</span>
                <span class="n">intermediate_graph_degree</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                <span class="n">graph_degree</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                <span class="n">build_algo</span><span class="o">=</span><span class="s2">&quot;nn_descent&quot;</span>
            <span class="p">)</span>

            <span class="n">index</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">cagra</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">index_params</span><span class="p">,</span> <span class="n">gpu_embeddings</span><span class="p">)</span>

            <span class="n">indexing_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            <span class="n">memory_after</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="c1"># Query benchmark</span>
            <span class="n">query_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">gpu_queries</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

            <span class="n">search_params</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">cagra</span><span class="o">.</span><span class="n">SearchParams</span><span class="p">(</span>
                <span class="n">itopk_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                <span class="n">search_width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">max_iterations</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">algo</span><span class="o">=</span><span class="s2">&quot;single_cta&quot;</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_embeddings</span><span class="p">)):</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">gpu_queries</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">cagra</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                    <span class="n">search_params</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span>
                <span class="p">)</span>
                <span class="n">cp</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="o">.</span><span class="n">null</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
                <span class="n">query_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

            <span class="n">avg_query_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">query_times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>

            <span class="c1"># GPU memory usage</span>
            <span class="n">gpu_memory_mb</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">get_default_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">used_bytes</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS CAGRA&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_docs&quot;</span><span class="p">:</span> <span class="n">num_docs</span><span class="p">,</span>
                <span class="s2">&quot;indexing_time_s&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">indexing_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_query_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s2">&quot;memory_usage_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">memory_after</span> <span class="o">-</span> <span class="n">memory_before</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;gpu_memory_mb&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">gpu_memory_mb</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;throughput_docs_per_sec&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">num_docs</span> <span class="o">/</span> <span class="n">indexing_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="s2">&quot;graph_degree&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;cuVS CAGRA&quot;</span><span class="p">,</span>
                <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;failed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_cuvs_benchmark</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run comprehensive cuVS benchmark&quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">test_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]</span>

        <span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;IVF-Flat&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_cuvs_ivf_flat</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;IVF-PQ&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_cuvs_ivf_pq</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;CAGRA&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_cuvs_cagra</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸš€ Starting cuVS Benchmark on Jetson&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">algo_name</span><span class="p">,</span> <span class="n">benchmark_func</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ”¬ Testing </span><span class="si">{</span><span class="n">algo_name</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">num_docs</span> <span class="ow">in</span> <span class="n">test_sizes</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ğŸ“Š </span><span class="si">{</span><span class="n">num_docs</span><span class="si">}</span><span class="s2"> documents...&quot;</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark_func</span><span class="p">(</span><span class="n">num_docs</span><span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    âœ… Index: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;indexing_time_s&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s, &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;Query: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;avg_query_time_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    âŒ Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_cuvs_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate cuVS performance report&quot;&quot;&quot;</span>
        <span class="n">successful_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">successful_results</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;No successful cuVS benchmarks to report.&quot;</span>

        <span class="n">report</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ† NVIDIA cuVS PERFORMANCE REPORT ON JETSON</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Performance by algorithm</span>
        <span class="n">algorithms</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;algorithm&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">successful_results</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
            <span class="n">algo_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">successful_results</span> <span class="k">if</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;algorithm&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">algo</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">algo_results</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ”¬ </span><span class="si">{</span><span class="n">algo</span><span class="si">}</span><span class="s2"> PERFORMANCE:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Docs&#39;</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Index(s)&#39;</span><span class="si">:</span><span class="s2">&lt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Query(ms)&#39;</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;GPU(MB)&#39;</span><span class="si">:</span><span class="s2">&lt;10</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">algo_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;num_docs&quot;</span><span class="p">]):</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;num_docs&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;indexing_time_s&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;10.2f</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;avg_query_time_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;12.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;gpu_memory_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;10.1f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Performance comparison</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">successful_results</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">fastest_query</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;avg_query_time_ms&quot;</span><span class="p">])</span>
            <span class="n">fastest_index</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;indexing_time_s&quot;</span><span class="p">])</span>
            <span class="n">most_efficient</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">successful_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;gpu_memory_mb&quot;</span><span class="p">])</span>

            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ… BEST PERFORMERS:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;âš¡ Fastest Query: </span><span class="si">{</span><span class="n">fastest_query</span><span class="p">[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">fastest_query</span><span class="p">[</span><span class="s1">&#39;avg_query_time_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms)</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸš€ Fastest Index: </span><span class="si">{</span><span class="n">fastest_index</span><span class="p">[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">fastest_index</span><span class="p">[</span><span class="s1">&#39;indexing_time_s&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s)</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ğŸ’¾ Most Efficient: </span><span class="si">{</span><span class="n">most_efficient</span><span class="p">[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">most_efficient</span><span class="p">[</span><span class="s1">&#39;gpu_memory_mb&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">MB)</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Recommendations</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ğŸ¯ cuVS RECOMMENDATIONS:</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ IVF-Flat: Best for accuracy and moderate datasets</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ IVF-PQ: Best for memory-constrained large datasets</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ CAGRA: Best for ultra-fast queries on GPU</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;ğŸ”¹ Use GPU memory pooling for better performance</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">report</span>

<span class="c1"># Run cuVS benchmark</span>
<span class="k">if</span> <span class="n">cuvs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">cuvs_benchmark</span> <span class="o">=</span> <span class="n">CuVSBenchmark</span><span class="p">()</span>
    <span class="n">cuvs_results</span> <span class="o">=</span> <span class="n">cuvs_benchmark</span><span class="o">.</span><span class="n">run_cuvs_benchmark</span><span class="p">()</span>
    <span class="n">cuvs_report</span> <span class="o">=</span> <span class="n">cuvs_benchmark</span><span class="o">.</span><span class="n">generate_cuvs_report</span><span class="p">(</span><span class="n">cuvs_results</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cuvs_report</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âš ï¸ cuVS or CuPy not available. Install to run GPU-accelerated benchmarks.&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="expected-cuvs-performance-on-jetson-orin">ğŸ“Š Expected cuVS Performance on Jetson Orin<a class="headerlink" href="#expected-cuvs-performance-on-jetson-orin" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Docs</th>
<th>Indexing (s)</th>
<th>Query (ms)</th>
<th>GPU Memory (MB)</th>
<th>Speedup vs CPU</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IVF-Flat</strong></td>
<td>1000</td>
<td>0.08</td>
<td>0.3</td>
<td>12</td>
<td>15x</td>
</tr>
<tr>
<td><strong>IVF-Flat</strong></td>
<td>10000</td>
<td>0.45</td>
<td>0.5</td>
<td>95</td>
<td>18x</td>
</tr>
<tr>
<td><strong>IVF-PQ</strong></td>
<td>1000</td>
<td>0.12</td>
<td>0.4</td>
<td>8</td>
<td>12x</td>
</tr>
<tr>
<td><strong>IVF-PQ</strong></td>
<td>10000</td>
<td>0.68</td>
<td>0.7</td>
<td>35</td>
<td>14x</td>
</tr>
<tr>
<td><strong>CAGRA</strong></td>
<td>1000</td>
<td>0.25</td>
<td>0.2</td>
<td>18</td>
<td>25x</td>
</tr>
<tr>
<td><strong>CAGRA</strong></td>
<td>10000</td>
<td>1.2</td>
<td>0.3</td>
<td>120</td>
<td>30x</td>
</tr>
</tbody>
</table>
<h3 id="embedding-optimization-strategies">ğŸ”§ Embedding Optimization Strategies<a class="headerlink" href="#embedding-optimization-strategies" title="Permanent link">&para;</a></h3>
<h4 id="1-model-quantization"><strong>1. Model Quantization</strong><a class="headerlink" href="#1-model-quantization" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="k">def</span><span class="w"> </span><span class="nf">quantize_embedding_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Quantize embedding model for Jetson deployment&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="c1"># Dynamic quantization (CPU)</span>
    <span class="n">quantized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">quantize_dynamic</span><span class="p">(</span>
        <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">auto_model</span><span class="p">,</span>
        <span class="p">{</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">},</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">qint8</span>
    <span class="p">)</span>

    <span class="c1"># Replace the transformer in the model</span>
    <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">auto_model</span> <span class="o">=</span> <span class="n">quantized_model</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Usage</span>
<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">quantize_embedding_model</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
</code></pre></div>
<h4 id="2-tensorrt-optimization"><strong>2. TensorRT Optimization</strong><a class="headerlink" href="#2-tensorrt-optimization" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">tensorrt</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">trt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch2trt</span><span class="w"> </span><span class="kn">import</span> <span class="n">torch2trt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">optimize_with_tensorrt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimize embedding model with TensorRT&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Create example input</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="c1"># Convert to TensorRT</span>
    <span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> 
        <span class="p">[</span><span class="n">x</span><span class="p">],</span> 
        <span class="n">fp16_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Use FP16 for better performance</span>
        <span class="n">max_workspace_size</span><span class="o">=</span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">25</span>  <span class="c1"># 32MB workspace</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model_trt</span>
</code></pre></div>
<h4 id="3-batch-processing-optimization"><strong>3. Batch Processing Optimization</strong><a class="headerlink" href="#3-batch-processing-optimization" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">OptimizedEmbeddingProcessor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimized embedding processing for Jetson&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="c1"># Enable GPU if available</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode_optimized</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimized batch encoding&quot;&quot;&quot;</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Process in optimized batches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>

            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># Disable gradients for inference</span>
                <span class="n">batch_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
                    <span class="n">batch</span><span class="p">,</span>
                    <span class="n">convert_to_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">normalize_embeddings</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Normalize for cosine similarity</span>
                <span class="p">)</span>

            <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_embeddings</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h3 id="integration-with-langchain">ğŸ¯ Integration with LangChain<a class="headerlink" href="#integration-with-langchain" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.embeddings.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">Embeddings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CuVSEmbeddings</span><span class="p">(</span><span class="n">Embeddings</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;LangChain-compatible cuVS embeddings&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">OptimizedEmbeddingProcessor</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">embed_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Embed a list of documents&quot;&quot;&quot;</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">encode_optimized</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">embed_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Embed a single query&quot;&quot;&quot;</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">encode_optimized</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># Usage with LangChain</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">FAISS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.schema</span><span class="w"> </span><span class="kn">import</span> <span class="n">Document</span>

<span class="c1"># Create optimized embeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">CuVSEmbeddings</span><span class="p">()</span>

<span class="c1"># Create documents</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="s2">&quot;NVIDIA Jetson enables edge AI computing.&quot;</span><span class="p">),</span>
    <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="s2">&quot;cuVS provides GPU-accelerated vector search.&quot;</span><span class="p">),</span>
    <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="s2">&quot;LangChain simplifies RAG application development.&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Create vector store with optimized embeddings</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># Perform similarity search</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;What is Jetson used for?&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: </span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="performance-summary">ğŸ† Performance Summary<a class="headerlink" href="#performance-summary" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Optimization</th>
<th>Speedup</th>
<th>Memory Reduction</th>
<th>Accuracy Impact</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>cuVS GPU</strong></td>
<td>15-30x</td>
<td>-</td>
<td>Minimal</td>
</tr>
<tr>
<td><strong>Model Quantization</strong></td>
<td>2-3x</td>
<td>75%</td>
<td>&lt;2%</td>
</tr>
<tr>
<td><strong>TensorRT FP16</strong></td>
<td>1.5-2x</td>
<td>50%</td>
<td>&lt;1%</td>
</tr>
<tr>
<td><strong>Batch Processing</strong></td>
<td>3-5x</td>
<td>-</td>
<td>None</td>
</tr>
<tr>
<td><strong>Combined</strong></td>
<td>50-100x</td>
<td>60%</td>
<td>&lt;3%</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="lab-build-rag-app-with-multiple-backends-on-jetson">ğŸ§ª Lab: Build RAG App with Multiple Backends on Jetson<a class="headerlink" href="#lab-build-rag-app-with-multiple-backends-on-jetson" title="Permanent link">&para;</a></h2>
<h3 id="setup">ğŸ§° Setup<a class="headerlink" href="#setup" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>langchain<span class="w"> </span>llama-cpp-python<span class="w"> </span>chromadb<span class="w"> </span>faiss-cpu<span class="w"> </span>qdrant-client<span class="w"> </span>sentence-transformers
</code></pre></div>
<h3 id="step-1-load-and-split-document">ğŸ”¹ Step 1: Load and Split Document<a class="headerlink" href="#step-1-load-and-split-document" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.text_splitter</span><span class="w"> </span><span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="s2">&quot;data/jetson_guide.txt&quot;</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">chunks</span> <span class="o">=</span> <span class="n">splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-2-embed-and-index-choose-backend">ğŸ”¹ Step 2: Embed and Index (Choose Backend)<a class="headerlink" href="#step-2-embed-and-index-choose-backend" title="Permanent link">&para;</a></h3>
<h4 id="option-a-chromadb">Option A: ChromaDB<a class="headerlink" href="#option-a-chromadb" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.embeddings</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformerEmbeddings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chroma</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="n">SentenceTransformerEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">Chroma</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">persist_directory</span><span class="o">=</span><span class="s2">&quot;db_chroma&quot;</span><span class="p">)</span>
</code></pre></div>
<h4 id="option-b-faiss">Option B: FAISS<a class="headerlink" href="#option-b-faiss" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">FAISS</span>
<span class="n">faiss_store</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>
</code></pre></div>
<h4 id="option-c-qdrant-self-hosted-or-remote">Option C: Qdrant (self-hosted or remote)<a class="headerlink" href="#option-c-qdrant-self-hosted-or-remote" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">Qdrant</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qdrant_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">QdrantClient</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">QdrantClient</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;./qdrant_data&quot;</span><span class="p">)</span>
<span class="n">qdrant_store</span> <span class="o">=</span> <span class="n">Qdrant</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">client</span><span class="o">=</span><span class="n">client</span><span class="p">,</span> <span class="n">collection_name</span><span class="o">=</span><span class="s2">&quot;jetson_docs&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Convert any vector store to retriever:</p>
<div class="highlight"><pre><span></span><code><span class="n">retriever</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>
</code></pre></div>
<hr />
<h3 id="step-3-rag-with-multiple-model-inference-backends">ğŸ”¹ Step 3: RAG with Multiple Model Inference Backends<a class="headerlink" href="#step-3-rag-with-multiple-model-inference-backends" title="Permanent link">&para;</a></h3>
<h4 id="llama-cpp-backend-local-gguf-model">âœ… llama-cpp Backend (Local GGUF Model)<a class="headerlink" href="#llama-cpp-backend-local-gguf-model" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlamaCpp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chains</span><span class="w"> </span><span class="kn">import</span> <span class="n">RetrievalQA</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">LlamaCpp</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;/models/mistral.gguf&quot;</span><span class="p">,</span> <span class="n">n_gpu_layers</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="n">qa</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">qa</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;What is Jetson Orin Nano used for?&quot;</span><span class="p">))</span>
</code></pre></div>
<h4 id="ollama-backend-local-rest-api">âœ… Ollama Backend (Local REST API)<a class="headerlink" href="#ollama-backend-local-rest-api" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">ollama_llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;http://localhost:11434/v1&quot;</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;ollama&quot;</span><span class="p">)</span>
<span class="n">qa_ollama</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">ollama_llm</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">qa_ollama</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;What is Jetson Orin Nano used for?&quot;</span><span class="p">))</span>
</code></pre></div>
<hr />
<h2 id="lab-deliverables">ğŸ“‹ Lab Deliverables<a class="headerlink" href="#lab-deliverables" title="Permanent link">&para;</a></h2>
<ul>
<li>Run the same query across multiple vector DBs and model backends</li>
<li>
<p>Record differences in:</p>
</li>
<li>
<p>Latency</p>
</li>
<li>Answer quality</li>
<li>Memory usage</li>
<li>Submit a table comparing results</li>
</ul>
<hr />
<h2 id="use-cases-for-jetson-edge">ğŸ’¡ Use Cases for Jetson Edge<a class="headerlink" href="#use-cases-for-jetson-edge" title="Permanent link">&para;</a></h2>
<ul>
<li>Campus FAQ bots with private syllabus</li>
<li>On-device document search (manuals, code docs)</li>
<li>Assistive RAG chatbot with no internet</li>
</ul>
<hr />
<h2 id="summary">âœ… Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<ul>
<li>RAG augments LLMs with context-aware search</li>
<li>Vector DB options: Chroma, FAISS, Qdrant (all lightweight and Jetson-compatible)</li>
<li>Inference backends: llama.cpp and Ollama, both support GGUF models</li>
<li>Jetson can handle small-to-medium scale RAG locally with optimized models</li>
</ul>
<p>â†’ Next: <a href="10_local_ai_agents_jetson.md">Local AI Agents</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>