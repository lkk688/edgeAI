
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>My 05 cnn image processing jetson - Jetson Cyber & AI Summer Camp</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#learning-objectives" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Jetson Cyber &amp; AI Summer Camp" class="md-header__button md-logo" aria-label="Jetson Cyber & AI Summer Camp" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Jetson Cyber & AI Summer Camp
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              My 05 cnn image processing jetson
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Jetson Cyber &amp; AI Summer Camp" class="md-nav__button md-logo" aria-label="Jetson Cyber & AI Summer Camp" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Jetson Cyber & AI Summer Camp
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00_sjsujetsontool_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sjsujetsontool Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01a_nvidia_jetson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to NVIDIA Jetson
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01b_linux_networking_tools.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Linux and Networking
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Core Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Core Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_programming_env_python_cpp_cuda.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Programming Environment (Python/C++/CUDA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_accelerated_computing_python_cuda.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerated Python + CUDA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04a_numpy_pytorch_intro.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Numpy
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04b_pytorch_intro.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Cyber Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Cyber Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01b_linux_networking_tools.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux Networking Tools
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01c_packet_sniffing_monitoring.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Packet Sniffing & Monitoring
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01d_linux_cyber_defense_basics.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux Cyber Defense Tools
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01e_linux_cyber_attack_simulation.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulated Attacks & Detection
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    AI & LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            AI & LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_cnn_image_processing_jetson.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CNNs + Image Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_transformers_llms_jetson.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers & LLMs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07_nlp_applications_llm_optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP + Inference Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08_prompt_engineering_langchain_jetson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt Engineering
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09_rag_app_langchain_jetson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RAG Apps
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_local_ai_agents_jetson.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Local AI Agents
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Final Project
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Final Project
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_final_challenges_hackathon.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hackathon & Challenges
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      üéØ Learning Objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-learning-theoretical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      üß† Deep Learning Theoretical Foundations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üß† Deep Learning Theoretical Foundations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      What is Deep Learning?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Key Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-neural-network-basics" class="md-nav__link">
    <span class="md-ellipsis">
      1. Neural Network Basics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-deep-learning-vs-traditional-ml" class="md-nav__link">
    <span class="md-ellipsis">
      2. Deep Learning vs Traditional ML
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-why-deep-learning-for-images" class="md-nav__link">
    <span class="md-ellipsis">
      3. Why Deep Learning for Images?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-operation" class="md-nav__link">
    <span class="md-ellipsis">
      Convolution Operation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cnn-architecture-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      üèóÔ∏è CNN Architecture Deep Dive
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üèóÔ∏è CNN Architecture Deep Dive">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNNs)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-layer-types" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Layer Types
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN Layer Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-convolutional-layer" class="md-nav__link">
    <span class="md-ellipsis">
      1. Convolutional Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-activation-layer" class="md-nav__link">
    <span class="md-ellipsis">
      2. Activation Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      3. Pooling Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-normalization-layer" class="md-nav__link">
    <span class="md-ellipsis">
      4. Normalization Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-fully-connected-layer" class="md-nav__link">
    <span class="md-ellipsis">
      5. Fully Connected Layer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-architecture-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      CNN Architecture Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cnn-implementation-with-jetson-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      üíª CNN Implementation with Jetson Toolkit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üíª CNN Implementation with Jetson Toolkit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cifar-10-classification-example" class="md-nav__link">
    <span class="md-ellipsis">
      CIFAR-10 Classification Example
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CIFAR-10 Classification Example">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-cnn-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Basic CNN Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-preparation-and-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Preparation and Augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Training Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualization-and-monitoring" class="md-nav__link">
    <span class="md-ellipsis">
      Visualization and Monitoring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#usage-example" class="md-nav__link">
    <span class="md-ellipsis">
      Usage Example
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      üèõÔ∏è Advanced CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üèõÔ∏è Advanced CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resnet-residual-networks" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet (Residual Networks)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResNet (Residual Networks)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-resnet-components" class="md-nav__link">
    <span class="md-ellipsis">
      Key ResNet Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-resnet-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Custom ResNet Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mobilenet-efficient-cnn-for-mobile-devices" class="md-nav__link">
    <span class="md-ellipsis">
      MobileNet - Efficient CNN for Mobile Devices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MobileNet - Efficient CNN for Mobile Devices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-mobilenet-features" class="md-nav__link">
    <span class="md-ellipsis">
      Key MobileNet Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mobilenet-in-jetson-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      MobileNet in Jetson Toolkit
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#efficientnet-compound-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      EfficientNet - Compound Scaling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EfficientNet - Compound Scaling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-efficientnet-innovations" class="md-nav__link">
    <span class="md-ellipsis">
      Key EfficientNet Innovations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#efficientnet-in-jetson-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      EfficientNet in Jetson Toolkit
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jetson-specific-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      ‚öôÔ∏è Jetson-Specific Optimizations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="‚öôÔ∏è Jetson-Specific Optimizations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-memory-management-for-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      1. Memory Management for Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Memory Management for Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-optimization-features-in-jetson-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Optimization Features in Jetson Toolkit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolkit-memory-management-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Toolkit Memory Management Usage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-model-quantization-for-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      2. Model Quantization for Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Model Quantization for Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization-techniques-in-jetson-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization Techniques in Jetson Toolkit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-features" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolkit-quantization-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Toolkit Quantization Usage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-tensorrt-optimization-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      3. TensorRT Optimization Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. TensorRT Optimization Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-optimization-features-in-jetson-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT Optimization Features in Jetson Toolkit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorrt-optimization-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT Optimization Workflow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolkit-tensorrt-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Toolkit TensorRT Usage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#production-deployment-on-jetson" class="md-nav__link">
    <span class="md-ellipsis">
      üöÄ Production Deployment on Jetson
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üöÄ Production Deployment on Jetson">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#real-time-image-classification-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Real-time Image Classification Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Real-time Image Classification Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#real-time-inference-features" class="md-nav__link">
    <span class="md-ellipsis">
      Real-time Inference Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#production-pipeline-components" class="md-nav__link">
    <span class="md-ellipsis">
      Production Pipeline Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deployment-usage-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Deployment Usage Examples
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comprehensive-lab-advanced-cnn-implementation-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      üß™ Comprehensive Lab: Advanced CNN Implementation and Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üß™ Comprehensive Lab: Advanced CNN Implementation and Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lab-overview" class="md-nav__link">
    <span class="md-ellipsis">
      Lab Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-objectives_1" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Objectives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-1-environment-setup-and-toolkit-installation" class="md-nav__link">
    <span class="md-ellipsis">
      Part 1: Environment Setup and Toolkit Installation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 1: Environment Setup and Toolkit Installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-install-jetson-cnn-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Install Jetson CNN Toolkit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-dataset-preparation-with-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Dataset Preparation with Toolkit
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-2-model-training-with-jetson-cnn-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Part 2: Model Training with Jetson CNN Toolkit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 2: Model Training with Jetson CNN Toolkit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-training-framework" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Training Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-model-comparison-framework" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Model Comparison Framework
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-3-model-training-and-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Part 3: Model Training and Comparison
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 3: Model Training and Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-train-multiple-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Train Multiple Architectures
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-4-jetson-optimization-and-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      Part 4: Jetson Optimization and Deployment
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 4: Jetson Optimization and Deployment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-performance-benchmarking" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Performance Benchmarking
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-5-real-time-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      Part 5: Real-time Deployment
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 5: Real-time Deployment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-deploy-best-model-for-real-time-inference" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Deploy Best Model for Real-time Inference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-deliverables" class="md-nav__link">
    <span class="md-ellipsis">
      Lab Deliverables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lab Deliverables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#required-deliverables" class="md-nav__link">
    <span class="md-ellipsis">
      Required Deliverables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bonus-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      Bonus Challenges
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Summary and Next Steps
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Summary and Next Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-youve-accomplished" class="md-nav__link">
    <span class="md-ellipsis">
      What You've Accomplished
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next Steps
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preprocess-input" class="md-nav__link">
    <span class="md-ellipsis">
      Preprocess input
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Run inference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<p>üß† Deep Learning &amp; CNNs for Image Classification on Jetson</p>
<h2 id="learning-objectives">üéØ Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<p>By the end of this tutorial, you will:
- Understand deep learning fundamentals and CNN architecture
- Implement basic and advanced CNN models using the Jetson CNN Toolkit
- Optimize CNN inference on Jetson devices using various techniques
- Deploy production-ready image classification systems</p>
<hr />
<h2 id="deep-learning-theoretical-foundations">üß† Deep Learning Theoretical Foundations<a class="headerlink" href="#deep-learning-theoretical-foundations" title="Permanent link">&para;</a></h2>
<h3 id="what-is-deep-learning"><strong>What is Deep Learning?</strong><a class="headerlink" href="#what-is-deep-learning" title="Permanent link">&para;</a></h3>
<p>Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence "deep") to model and understand complex patterns in data. For image classification, deep learning has revolutionized computer vision by automatically learning hierarchical feature representations.</p>
<h3 id="key-concepts"><strong>Key Concepts</strong><a class="headerlink" href="#key-concepts" title="Permanent link">&para;</a></h3>
<h4 id="1-neural-network-basics"><strong>1. Neural Network Basics</strong><a class="headerlink" href="#1-neural-network-basics" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Neuron</strong>: Basic computational unit that applies weights, bias, and activation function</li>
<li><strong>Layer</strong>: Collection of neurons that process input simultaneously</li>
<li><strong>Forward Propagation</strong>: Data flows from input to output through layers</li>
<li><strong>Backpropagation</strong>: Error flows backward to update weights during training</li>
</ul>
<h4 id="2-deep-learning-vs-traditional-ml"><strong>2. Deep Learning vs Traditional ML</strong><a class="headerlink" href="#2-deep-learning-vs-traditional-ml" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Traditional ML</th>
<th>Deep Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Feature Engineering</strong></td>
<td>Manual feature extraction</td>
<td>Automatic feature learning</td>
</tr>
<tr>
<td><strong>Data Requirements</strong></td>
<td>Works with small datasets</td>
<td>Requires large datasets</td>
</tr>
<tr>
<td><strong>Computational Cost</strong></td>
<td>Lower</td>
<td>Higher</td>
</tr>
<tr>
<td><strong>Performance</strong></td>
<td>Good for simple patterns</td>
<td>Excellent for complex patterns</td>
</tr>
<tr>
<td><strong>Interpretability</strong></td>
<td>Higher</td>
<td>Lower (black box)</td>
</tr>
</tbody>
</table>
<h4 id="3-why-deep-learning-for-images"><strong>3. Why Deep Learning for Images?</strong><a class="headerlink" href="#3-why-deep-learning-for-images" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Hierarchical Learning</strong>: Lower layers detect edges, higher layers detect objects</li>
<li><strong>Translation Invariance</strong>: Can recognize objects regardless of position</li>
<li><strong>Scale Invariance</strong>: Can handle objects of different sizes</li>
<li><strong>Robustness</strong>: Handles variations in lighting, rotation, and occlusion</li>
</ul>
<h3 id="mathematical-foundations"><strong>Mathematical Foundations</strong><a class="headerlink" href="#mathematical-foundations" title="Permanent link">&para;</a></h3>
<h4 id="convolution-operation"><strong>Convolution Operation</strong><a class="headerlink" href="#convolution-operation" title="Permanent link">&para;</a></h4>
<p>The convolution operation is fundamental to CNNs. It involves sliding a filter (kernel) across an input image to detect features. The mathematical representation is:</p>
<p><strong>Output[i,j] = Œ£ Œ£ Input[i+m, j+n] * Kernel[m,n]</strong></p>
<p>The Jetson CNN Toolkit includes a demonstration of 2D convolution operations for educational purposes, showing how edge detection kernels work on sample images.</p>
<h4 id="activation-functions"><strong>Activation Functions</strong><a class="headerlink" href="#activation-functions" title="Permanent link">&para;</a></h4>
<p>Activation functions introduce non-linearity into neural networks, enabling them to learn complex patterns:</p>
<ul>
<li><strong>ReLU (Rectified Linear Unit)</strong>: f(x) = max(0, x) - Most commonly used</li>
<li><strong>Sigmoid</strong>: f(x) = 1/(1+e^(-x)) - Outputs between 0 and 1</li>
<li><strong>Tanh</strong>: f(x) = tanh(x) - Outputs between -1 and 1</li>
<li><strong>Leaky ReLU</strong>: f(x) = max(0.01x, x) - Prevents dying ReLU problem</li>
</ul>
<p>The toolkit includes visualization capabilities for comparing different activation functions and their characteristics.</p>
<hr />
<h2 id="cnn-architecture-deep-dive">üèóÔ∏è CNN Architecture Deep Dive<a class="headerlink" href="#cnn-architecture-deep-dive" title="Permanent link">&para;</a></h2>
<h3 id="convolutional-neural-networks-cnns"><strong>Convolutional Neural Networks (CNNs)</strong><a class="headerlink" href="#convolutional-neural-networks-cnns" title="Permanent link">&para;</a></h3>
<p>CNNs are specialized deep neural networks designed for processing grid-like data such as images. They use convolution operations to detect local features and build hierarchical representations.</p>
<h3 id="cnn-layer-types"><strong>CNN Layer Types</strong><a class="headerlink" href="#cnn-layer-types" title="Permanent link">&para;</a></h3>
<h4 id="1-convolutional-layer"><strong>1. Convolutional Layer</strong><a class="headerlink" href="#1-convolutional-layer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Purpose</strong>: Feature extraction using learnable filters</li>
<li><strong>Parameters</strong>: Filter size, stride, padding, number of filters</li>
<li><strong>Output</strong>: Feature maps highlighting detected patterns</li>
</ul>
<h4 id="2-activation-layer"><strong>2. Activation Layer</strong><a class="headerlink" href="#2-activation-layer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Purpose</strong>: Introduce non-linearity</li>
<li><strong>Common</strong>: ReLU, Leaky ReLU, ELU</li>
<li><strong>Effect</strong>: Enables learning of complex patterns</li>
</ul>
<h4 id="3-pooling-layer"><strong>3. Pooling Layer</strong><a class="headerlink" href="#3-pooling-layer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Purpose</strong>: Spatial downsampling and translation invariance</li>
<li><strong>Types</strong>: Max pooling, Average pooling, Global pooling</li>
<li><strong>Benefits</strong>: Reduces computational cost and overfitting</li>
</ul>
<h4 id="4-normalization-layer"><strong>4. Normalization Layer</strong><a class="headerlink" href="#4-normalization-layer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Purpose</strong>: Stabilize training and improve convergence</li>
<li><strong>Types</strong>: Batch Normalization, Layer Normalization, Group Normalization</li>
<li><strong>Benefits</strong>: Faster training, better generalization</li>
</ul>
<h4 id="5-fully-connected-layer"><strong>5. Fully Connected Layer</strong><a class="headerlink" href="#5-fully-connected-layer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Purpose</strong>: Final classification or regression</li>
<li><strong>Position</strong>: Usually at the end of the network</li>
<li><strong>Function</strong>: Maps features to output classes</li>
</ul>
<h3 id="cnn-architecture-implementation"><strong>CNN Architecture Implementation</strong><a class="headerlink" href="#cnn-architecture-implementation" title="Permanent link">&para;</a></h3>
<p>The Jetson CNN Toolkit provides a comprehensive <code>BasicCNN</code> class that demonstrates proper CNN architecture design:</p>
<ul>
<li><strong>Feature Extraction Layers</strong>: Three convolutional blocks with increasing channel depth (32‚Üí64‚Üí128)</li>
<li><strong>Batch Normalization</strong>: Applied after each convolution for training stability</li>
<li><strong>Pooling Strategy</strong>: Max pooling for spatial downsampling, adaptive pooling for variable input sizes</li>
<li><strong>Classification Head</strong>: Fully connected layers with dropout for regularization</li>
</ul>
<p>The toolkit's <code>BasicCNN</code> implementation supports configurable input channels and output classes, making it suitable for various image classification tasks from CIFAR-10 to ImageNet-scale problems.</p>
<hr />
<h2 id="cnn-implementation-with-jetson-toolkit">üíª CNN Implementation with Jetson Toolkit<a class="headerlink" href="#cnn-implementation-with-jetson-toolkit" title="Permanent link">&para;</a></h2>
<h3 id="cifar-10-classification-example"><strong>CIFAR-10 Classification Example</strong><a class="headerlink" href="#cifar-10-classification-example" title="Permanent link">&para;</a></h3>
<p>The Jetson CNN Toolkit provides a comprehensive implementation for image classification tasks. The toolkit includes several CNN architectures optimized for NVIDIA Jetson devices.</p>
<h4 id="basic-cnn-architecture"><strong>Basic CNN Architecture</strong><a class="headerlink" href="#basic-cnn-architecture" title="Permanent link">&para;</a></h4>
<p>The toolkit's <code>BasicCNN</code> class demonstrates a well-structured CNN design:</p>
<ul>
<li><strong>Convolutional Blocks</strong>: Three sequential blocks with increasing feature depth (32‚Üí64‚Üí128 channels)</li>
<li><strong>Batch Normalization</strong>: Applied after each convolution for training stability</li>
<li><strong>Pooling Strategy</strong>: Max pooling for spatial downsampling</li>
<li><strong>Classification Head</strong>: Fully connected layers with dropout regularization</li>
<li><strong>Adaptive Design</strong>: Supports variable input sizes through adaptive pooling</li>
</ul>
<h4 id="data-preparation-and-augmentation"><strong>Data Preparation and Augmentation</strong><a class="headerlink" href="#data-preparation-and-augmentation" title="Permanent link">&para;</a></h4>
<p>The Jetson CNN Toolkit includes comprehensive data handling capabilities:</p>
<ul>
<li><strong>Dataset Support</strong>: CIFAR-10, ImageNet, and custom datasets</li>
<li><strong>Data Augmentation</strong>: Random horizontal flip, rotation, color jittering, and normalization</li>
<li><strong>Efficient Loading</strong>: Optimized data loaders with configurable batch sizes and worker processes</li>
<li><strong>Preprocessing Pipeline</strong>: Automatic image preprocessing with dataset-specific normalization values</li>
</ul>
<h4 id="training-pipeline"><strong>Training Pipeline</strong><a class="headerlink" href="#training-pipeline" title="Permanent link">&para;</a></h4>
<p>The Jetson CNN Toolkit provides a comprehensive training system:</p>
<ul>
<li><strong>Optimizer Support</strong>: Adam, SGD, and other optimizers with configurable learning rates</li>
<li><strong>Loss Functions</strong>: Cross-entropy, focal loss, and custom loss implementations</li>
<li><strong>Learning Rate Scheduling</strong>: Step decay, cosine annealing, and adaptive scheduling</li>
<li><strong>Training Monitoring</strong>: Real-time loss and accuracy tracking with progress visualization</li>
<li><strong>Validation</strong>: Automatic validation during training with early stopping capabilities</li>
<li><strong>Device Management</strong>: Automatic GPU/CPU detection and memory optimization for Jetson devices</li>
</ul>
<h4 id="visualization-and-monitoring"><strong>Visualization and Monitoring</strong><a class="headerlink" href="#visualization-and-monitoring" title="Permanent link">&para;</a></h4>
<p>The toolkit includes comprehensive visualization capabilities:</p>
<ul>
<li><strong>Training Curves</strong>: Real-time plotting of loss and accuracy metrics</li>
<li><strong>Performance Metrics</strong>: Detailed accuracy, precision, recall, and F1-score tracking</li>
<li><strong>Model Visualization</strong>: Architecture diagrams and feature map visualization</li>
<li><strong>Export Options</strong>: Save training history and model checkpoints automatically</li>
</ul>
<h4 id="usage-example"><strong>Usage Example</strong><a class="headerlink" href="#usage-example" title="Permanent link">&para;</a></h4>
<p>The Jetson CNN Toolkit provides a simple command-line interface for training:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Train a BasicCNN on CIFAR-10</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>train<span class="w"> </span>--model<span class="w"> </span>BasicCNN<span class="w"> </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span>--epochs<span class="w"> </span><span class="m">20</span>

<span class="c1"># Train with custom parameters</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>train<span class="w"> </span>--model<span class="w"> </span>CustomResNet<span class="w"> </span>--dataset<span class="w"> </span>imagenet<span class="w"> </span>--batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span>--lr<span class="w"> </span><span class="m">0</span>.001
</code></pre></div>
<hr />
<h2 id="advanced-cnn-architectures">üèõÔ∏è Advanced CNN Architectures<a class="headerlink" href="#advanced-cnn-architectures" title="Permanent link">&para;</a></h2>
<h3 id="resnet-residual-networks"><strong>ResNet (Residual Networks)</strong><a class="headerlink" href="#resnet-residual-networks" title="Permanent link">&para;</a></h3>
<p>ResNet introduced skip connections to solve the vanishing gradient problem in deep networks.</p>
<h4 id="key-resnet-components"><strong>Key ResNet Components</strong><a class="headerlink" href="#key-resnet-components" title="Permanent link">&para;</a></h4>
<p><strong>Residual Blocks</strong>: The fundamental building blocks that implement skip connections, allowing gradients to flow directly through the network during backpropagation.</p>
<p><strong>Skip Connections</strong>: Direct pathways that add the input to the output of a block, enabling identity mapping and solving the degradation problem in deep networks.</p>
<p><strong>Bottleneck Design</strong>: Efficient architecture using 1x1 convolutions to reduce computational complexity while maintaining representational power.</p>
<h4 id="custom-resnet-implementation"><strong>Custom ResNet Implementation</strong><a class="headerlink" href="#custom-resnet-implementation" title="Permanent link">&para;</a></h4>
<p>The Jetson CNN Toolkit includes a <code>CustomResNet</code> class optimized for edge deployment:</p>
<ul>
<li><strong>Modular Design</strong>: Built using <code>ResidualBlock</code> components for easy customization</li>
<li><strong>Configurable Depth</strong>: Supports different layer configurations (ResNet-18, ResNet-34, etc.)</li>
<li><strong>Jetson Optimization</strong>: Memory-efficient implementation suitable for embedded deployment</li>
<li><strong>Skip Connection Handling</strong>: Automatic dimension matching for different stride and channel configurations</li>
</ul>
<p>The implementation demonstrates proper residual learning with batch normalization, ReLU activations, and adaptive pooling for variable input sizes.</p>
<h3 id="mobilenet-efficient-cnn-for-mobile-devices"><strong>MobileNet - Efficient CNN for Mobile Devices</strong><a class="headerlink" href="#mobilenet-efficient-cnn-for-mobile-devices" title="Permanent link">&para;</a></h3>
<p>MobileNet uses depthwise separable convolutions to reduce computational cost while maintaining accuracy.</p>
<h4 id="key-mobilenet-features"><strong>Key MobileNet Features</strong><a class="headerlink" href="#key-mobilenet-features" title="Permanent link">&para;</a></h4>
<p><strong>Depthwise Separable Convolutions</strong>: Split standard convolutions into depthwise and pointwise operations, dramatically reducing computational cost.</p>
<p><strong>Width Multiplier</strong>: Allows scaling the network size by adjusting the number of channels, enabling deployment on resource-constrained devices.</p>
<p><strong>Efficient Architecture</strong>: Designed specifically for mobile and embedded applications with minimal accuracy loss.</p>
<h4 id="mobilenet-in-jetson-toolkit"><strong>MobileNet in Jetson Toolkit</strong><a class="headerlink" href="#mobilenet-in-jetson-toolkit" title="Permanent link">&para;</a></h4>
<p>The toolkit includes an optimized MobileNet implementation:</p>
<ul>
<li><strong>Jetson-Optimized</strong>: Configured with appropriate width multipliers for different Jetson models</li>
<li><strong>Depthwise Separable Blocks</strong>: Efficient implementation of the core MobileNet building blocks</li>
<li><strong>Flexible Scaling</strong>: Configurable width multipliers (0.25, 0.5, 0.75, 1.0) for different performance requirements</li>
<li><strong>Memory Efficient</strong>: Optimized for Jetson's memory constraints while maintaining inference speed</li>
</ul>
<h3 id="efficientnet-compound-scaling"><strong>EfficientNet - Compound Scaling</strong><a class="headerlink" href="#efficientnet-compound-scaling" title="Permanent link">&para;</a></h3>
<p>EfficientNet uses compound scaling to balance network depth, width, and resolution for optimal efficiency.</p>
<h4 id="key-efficientnet-innovations"><strong>Key EfficientNet Innovations</strong><a class="headerlink" href="#key-efficientnet-innovations" title="Permanent link">&para;</a></h4>
<p><strong>Compound Scaling</strong>: Systematically scales network depth, width, and resolution using a compound coefficient, achieving better accuracy-efficiency trade-offs.</p>
<p><strong>Mobile Inverted Bottleneck (MBConv)</strong>: Advanced building blocks that combine inverted residuals, depthwise convolutions, and squeeze-and-excitation modules.</p>
<p><strong>Neural Architecture Search (NAS)</strong>: The base architecture was discovered through automated search, optimizing for both accuracy and efficiency.</p>
<p><strong>Squeeze-and-Excitation</strong>: Attention mechanism that adaptively recalibrates channel-wise feature responses.</p>
<h4 id="efficientnet-in-jetson-toolkit"><strong>EfficientNet in Jetson Toolkit</strong><a class="headerlink" href="#efficientnet-in-jetson-toolkit" title="Permanent link">&para;</a></h4>
<p>The toolkit provides EfficientNet variants optimized for Jetson deployment:</p>
<ul>
<li><strong>Jetson-Tuned Scaling</strong>: Pre-configured compound coefficients optimized for different Jetson models</li>
<li><strong>MBConv Blocks</strong>: Efficient implementation of mobile inverted bottleneck convolutions</li>
<li><strong>Memory Optimization</strong>: Reduced precision and optimized memory access patterns</li>
<li><strong>Flexible Variants</strong>: Support for EfficientNet-B0 through B7 with Jetson-specific modifications</li>
<li><strong>SE Module Integration</strong>: Optimized squeeze-and-excitation implementation for edge devices</li>
</ul>
<hr />
<h2 id="jetson-specific-optimizations">‚öôÔ∏è Jetson-Specific Optimizations<a class="headerlink" href="#jetson-specific-optimizations" title="Permanent link">&para;</a></h2>
<h3 id="1-memory-management-for-jetson"><strong>1. Memory Management for Jetson</strong><a class="headerlink" href="#1-memory-management-for-jetson" title="Permanent link">&para;</a></h3>
<p>Efficient memory management is crucial for optimal performance on resource-constrained Jetson devices.</p>
<h4 id="memory-optimization-features-in-jetson-toolkit"><strong>Memory Optimization Features in Jetson Toolkit</strong><a class="headerlink" href="#memory-optimization-features-in-jetson-toolkit" title="Permanent link">&para;</a></h4>
<p><strong>System Memory Monitoring</strong>: Real-time tracking of system RAM usage, available memory, and memory pressure indicators to prevent out-of-memory conditions.</p>
<p><strong>GPU Memory Management</strong>: Comprehensive CUDA memory monitoring including allocated, cached, and free GPU memory with automatic cleanup routines.</p>
<p><strong>Garbage Collection</strong>: Intelligent Python garbage collection and CUDA cache clearing to free up memory during training and inference.</p>
<p><strong>Power Mode Control</strong>: Automated power mode switching (MAXN, 15W, 10W) based on workload requirements and thermal constraints.</p>
<p><strong>Clock Speed Optimization</strong>: Integration with jetson_clocks utility for maximum performance when needed.</p>
<h4 id="toolkit-memory-management-usage"><strong>Toolkit Memory Management Usage</strong><a class="headerlink" href="#toolkit-memory-management-usage" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Monitor memory usage during training</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>train<span class="w"> </span>--model<span class="w"> </span>BasicCNN<span class="w"> </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span>--monitor-memory

<span class="c1"># Optimize memory for inference</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>inference<span class="w"> </span>--optimize-memory<span class="w"> </span>--power-mode<span class="w"> </span>15W
</code></pre></div>
<h3 id="2-model-quantization-for-jetson"><strong>2. Model Quantization for Jetson</strong><a class="headerlink" href="#2-model-quantization-for-jetson" title="Permanent link">&para;</a></h3>
<p>Quantization reduces model precision from FP32 to INT8, significantly improving inference speed and reducing memory usage on Jetson devices.</p>
<h4 id="quantization-techniques-in-jetson-toolkit"><strong>Quantization Techniques in Jetson Toolkit</strong><a class="headerlink" href="#quantization-techniques-in-jetson-toolkit" title="Permanent link">&para;</a></h4>
<p><strong>Post-Training Quantization (PTQ)</strong>: Automatic conversion of trained FP32 models to INT8 without retraining, using calibration datasets for optimal accuracy preservation.</p>
<p><strong>Quantization-Aware Training (QAT)</strong>: Training models with quantization simulation to achieve better accuracy in quantized form.</p>
<p><strong>Dynamic Quantization</strong>: Runtime quantization of weights while keeping activations in FP32 for balanced performance and accuracy.</p>
<p><strong>Static Quantization</strong>: Full INT8 quantization of both weights and activations using calibration data for maximum performance.</p>
<h4 id="quantization-features"><strong>Quantization Features</strong><a class="headerlink" href="#quantization-features" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Automatic Calibration</strong>: Uses representative data samples to determine optimal quantization parameters</li>
<li><strong>Accuracy Preservation</strong>: Advanced techniques to minimize accuracy loss during quantization</li>
<li><strong>Jetson Optimization</strong>: Quantization schemes optimized for Jetson's Tensor Cores and DLA</li>
<li><strong>Flexible Precision</strong>: Support for mixed-precision quantization (FP16/INT8)</li>
</ul>
<h4 id="toolkit-quantization-usage"><strong>Toolkit Quantization Usage</strong><a class="headerlink" href="#toolkit-quantization-usage" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Apply post-training quantization</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>optimize<span class="w"> </span>--precision<span class="w"> </span>int8<span class="w"> </span>--model-path<span class="w"> </span>trained_model.pth

<span class="c1"># Quantization-aware training</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>train<span class="w"> </span>--model<span class="w"> </span>ResNet<span class="w"> </span>--quantize<span class="w"> </span>--precision<span class="w"> </span>int8
</code></pre></div>
<h3 id="3-tensorrt-optimization-pipeline"><strong>3. TensorRT Optimization Pipeline</strong><a class="headerlink" href="#3-tensorrt-optimization-pipeline" title="Permanent link">&para;</a></h3>
<p>TensorRT is NVIDIA's high-performance deep learning inference optimizer and runtime library, essential for maximizing performance on Jetson devices.</p>
<h4 id="tensorrt-optimization-features-in-jetson-toolkit"><strong>TensorRT Optimization Features in Jetson Toolkit</strong><a class="headerlink" href="#tensorrt-optimization-features-in-jetson-toolkit" title="Permanent link">&para;</a></h4>
<p><strong>Automatic ONNX Export</strong>: Seamless conversion of PyTorch models to ONNX format with optimized export parameters for TensorRT compatibility.</p>
<p><strong>Engine Building</strong>: Automated TensorRT engine construction with Jetson-specific optimizations including:
- <strong>FP16 Precision</strong>: Leverages Jetson's Tensor Cores for 2x performance improvement
- <strong>INT8 Calibration</strong>: Advanced quantization with accuracy preservation
- <strong>Dynamic Shapes</strong>: Support for variable input sizes
- <strong>Layer Fusion</strong>: Automatic optimization of network topology</p>
<p><strong>Memory Management</strong>: Efficient GPU memory allocation and buffer management for optimal inference performance.</p>
<p><strong>Inference Engine</strong>: High-performance inference runtime with:
- <strong>Asynchronous Execution</strong>: Non-blocking inference for maximum throughput
- <strong>Batch Processing</strong>: Optimized batch inference for multiple inputs
- <strong>Memory Pooling</strong>: Reusable memory buffers to minimize allocation overhead</p>
<h4 id="tensorrt-optimization-workflow"><strong>TensorRT Optimization Workflow</strong><a class="headerlink" href="#tensorrt-optimization-workflow" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Model Export</strong>: Convert trained PyTorch model to ONNX format</li>
<li><strong>Engine Building</strong>: Create optimized TensorRT engine with precision selection</li>
<li><strong>Calibration</strong>: Generate INT8 calibration data for quantized models</li>
<li><strong>Deployment</strong>: Load and run optimized engine for inference</li>
</ol>
<h4 id="toolkit-tensorrt-usage"><strong>Toolkit TensorRT Usage</strong><a class="headerlink" href="#toolkit-tensorrt-usage" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Optimize model with TensorRT FP16</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>optimize<span class="w"> </span>--precision<span class="w"> </span>fp16<span class="w"> </span>--model-path<span class="w"> </span>model.pth<span class="w"> </span>--output-engine<span class="w"> </span>model_fp16.trt

<span class="c1"># Optimize with INT8 quantization</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>optimize<span class="w"> </span>--precision<span class="w"> </span>int8<span class="w"> </span>--calibration-data<span class="w"> </span>./calibration<span class="w"> </span>--model-path<span class="w"> </span>model.pth

<span class="c1"># Benchmark TensorRT performance</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>benchmark<span class="w"> </span>--engine-path<span class="w"> </span>model_fp16.trt<span class="w"> </span>--batch-size<span class="w"> </span><span class="m">1</span>
</code></pre></div>
<hr />
<h2 id="production-deployment-on-jetson">üöÄ Production Deployment on Jetson<a class="headerlink" href="#production-deployment-on-jetson" title="Permanent link">&para;</a></h2>
<h3 id="real-time-image-classification-pipeline"><strong>Real-time Image Classification Pipeline</strong><a class="headerlink" href="#real-time-image-classification-pipeline" title="Permanent link">&para;</a></h3>
<p>The Jetson CNN Toolkit provides a complete production-ready deployment framework for real-time image classification applications.</p>
<h4 id="real-time-inference-features"><strong>Real-time Inference Features</strong><a class="headerlink" href="#real-time-inference-features" title="Permanent link">&para;</a></h4>
<p><strong>Multi-threaded Architecture</strong>: Optimized pipeline with separate threads for camera capture, inference processing, and display rendering to maximize throughput.</p>
<p><strong>Camera Integration</strong>: Native support for USB and CSI cameras with configurable resolution, frame rate, and buffer management.</p>
<p><strong>Model Format Support</strong>: Seamless loading of PyTorch models (.pth), TensorRT engines (.trt), and ONNX models with automatic format detection.</p>
<p><strong>Performance Monitoring</strong>: Real-time tracking of FPS, inference latency, memory usage, and thermal metrics with visual overlays.</p>
<p><strong>Adaptive Processing</strong>: Dynamic frame dropping and quality adjustment based on system load and thermal constraints.</p>
<h4 id="production-pipeline-components"><strong>Production Pipeline Components</strong><a class="headerlink" href="#production-pipeline-components" title="Permanent link">&para;</a></h4>
<p><strong>Image Preprocessing</strong>: Optimized preprocessing pipeline with GPU-accelerated transforms, normalization, and batching.</p>
<p><strong>Inference Engine</strong>: High-performance inference with support for:
- <strong>Asynchronous Processing</strong>: Non-blocking inference for maximum throughput
- <strong>Batch Optimization</strong>: Dynamic batching for improved GPU utilization
- <strong>Memory Pooling</strong>: Efficient memory management to prevent allocation overhead</p>
<p><strong>Post-processing</strong>: Fast result processing with confidence thresholding, class mapping, and visualization.</p>
<p><strong>Display Integration</strong>: Real-time visualization with performance overlays, confidence indicators, and classification results.</p>
<h4 id="deployment-usage-examples"><strong>Deployment Usage Examples</strong><a class="headerlink" href="#deployment-usage-examples" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Real-time classification with camera</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>inference<span class="w"> </span>--model-path<span class="w"> </span>model.trt<span class="w"> </span>--camera<span class="w"> </span><span class="m">0</span><span class="w"> </span>--display

<span class="c1"># Batch processing of video files</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>inference<span class="w"> </span>--model-path<span class="w"> </span>model.pth<span class="w"> </span>--input<span class="w"> </span>video.mp4<span class="w"> </span>--output<span class="w"> </span>results.mp4

<span class="c1"># Performance benchmarking</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>benchmark<span class="w"> </span>--model-path<span class="w"> </span>model.trt<span class="w"> </span>--batch-size<span class="w"> </span><span class="m">1</span><span class="w"> </span>--iterations<span class="w"> </span><span class="m">1000</span>

<span class="c1"># Production deployment with monitoring</span>
python<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>inference<span class="w"> </span>--model-path<span class="w"> </span>model.trt<span class="w"> </span>--monitor-performance<span class="w"> </span>--log-results
</code></pre></div>
<hr />
<h2 id="comprehensive-lab-advanced-cnn-implementation-and-optimization">üß™ Comprehensive Lab: Advanced CNN Implementation and Optimization<a class="headerlink" href="#comprehensive-lab-advanced-cnn-implementation-and-optimization" title="Permanent link">&para;</a></h2>
<h3 id="lab-overview"><strong>Lab Overview</strong><a class="headerlink" href="#lab-overview" title="Permanent link">&para;</a></h3>
<p>This comprehensive lab demonstrates how to use the Jetson CNN Toolkit for implementing, training, and optimizing CNN models for real-time image classification on Jetson devices.</p>
<h3 id="learning-objectives_1"><strong>Learning Objectives</strong><a class="headerlink" href="#learning-objectives_1" title="Permanent link">&para;</a></h3>
<ul>
<li>Master the Jetson CNN Toolkit for multiple CNN architectures</li>
<li>Apply Jetson-specific optimizations using the toolkit</li>
<li>Deploy real-time inference pipelines</li>
<li>Compare performance across different optimization techniques</li>
<li>Understand the complete ML pipeline from training to deployment</li>
</ul>
<h3 id="prerequisites"><strong>Prerequisites</strong><a class="headerlink" href="#prerequisites" title="Permanent link">&para;</a></h3>
<ul>
<li>Jetson Orin Nano with JetPack 5.0+</li>
<li>Python 3.8+ with pip</li>
<li>Camera module (USB or CSI)</li>
<li>16GB+ storage space</li>
<li>Basic understanding of deep learning concepts</li>
</ul>
<hr />
<h2 id="part-1-environment-setup-and-toolkit-installation"><strong>Part 1: Environment Setup and Toolkit Installation</strong><a class="headerlink" href="#part-1-environment-setup-and-toolkit-installation" title="Permanent link">&para;</a></h2>
<h3 id="11-install-jetson-cnn-toolkit"><strong>1.1 Install Jetson CNN Toolkit</strong><a class="headerlink" href="#11-install-jetson-cnn-toolkit" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Clone the toolkit repository</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/your-repo/jetson-cnn-toolkit.git
<span class="nb">cd</span><span class="w"> </span>jetson-cnn-toolkit

<span class="c1"># Install dependencies</span>
pip3<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt

<span class="c1"># Verify installation</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--help
</code></pre></div>
<h3 id="12-dataset-preparation-with-toolkit"><strong>1.2 Dataset Preparation with Toolkit</strong><a class="headerlink" href="#12-dataset-preparation-with-toolkit" title="Permanent link">&para;</a></h3>
<p>The toolkit provides automated dataset preparation and augmentation:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Download and prepare CIFAR-10 dataset</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>prepare-data<span class="w"> </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span>--augment

<span class="c1"># Verify dataset preparation</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>visualize-data<span class="w"> </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span>--samples<span class="w"> </span><span class="m">8</span>
</code></pre></div>
<p><strong>Dataset Features Provided by Toolkit:</strong>
- <strong>Automatic Download</strong>: CIFAR-10, ImageNet subset, and custom dataset support
- <strong>Smart Augmentation</strong>: Jetson-optimized data augmentation pipeline
- <strong>Memory-Efficient Loading</strong>: Optimized data loaders for Jetson memory constraints
- <strong>Validation Splitting</strong>: Automatic train/validation/test splits
- <strong>Visualization Tools</strong>: Built-in dataset exploration and sample visualization</p>
<hr />
<h2 id="part-2-model-training-with-jetson-cnn-toolkit"><strong>Part 2: Model Training with Jetson CNN Toolkit</strong><a class="headerlink" href="#part-2-model-training-with-jetson-cnn-toolkit" title="Permanent link">&para;</a></h2>
<h3 id="21-training-framework"><strong>2.1 Training Framework</strong><a class="headerlink" href="#21-training-framework" title="Permanent link">&para;</a></h3>
<p>The Jetson CNN Toolkit provides a comprehensive training framework optimized for Jetson devices:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Train a single model</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>train<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>resnet18<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--epochs<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning-rate<span class="w"> </span><span class="m">0</span>.001<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--optimizer<span class="w"> </span>adam<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--scheduler<span class="w"> </span>step<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--device<span class="w"> </span>cuda

<span class="c1"># Monitor training progress</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>monitor<span class="w"> </span>--experiment<span class="w"> </span>resnet18_cifar10
</code></pre></div>
<p><strong>Training Features Provided by Toolkit:</strong>
- <strong>Optimized Training Loop</strong>: Jetson-specific memory management and GPU utilization
- <strong>Multiple Optimizers</strong>: Adam, SGD, AdamW with automatic hyperparameter tuning
- <strong>Learning Rate Scheduling</strong>: Step, cosine, exponential, and plateau schedulers
- <strong>Early Stopping</strong>: Automatic training termination based on validation metrics
- <strong>Checkpointing</strong>: Automatic model saving and resuming from interruptions
- <strong>Mixed Precision</strong>: FP16 training for faster convergence and memory efficiency
- <strong>Real-time Monitoring</strong>: Live training metrics and resource utilization
- <strong>Validation Tracking</strong>: Automatic best model selection based on validation performance</p>
<h3 id="22-model-comparison-framework"><strong>2.2 Model Comparison Framework</strong><a class="headerlink" href="#22-model-comparison-framework" title="Permanent link">&para;</a></h3>
<p>The toolkit provides automated model comparison capabilities:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Compare multiple architectures</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>compare<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--models<span class="w"> </span>resnet18,mobilenet_v2,efficientnet_b0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--epochs<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--metrics<span class="w"> </span>accuracy,loss,inference_time,memory_usage

<span class="c1"># Generate comparison report</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>report<span class="w"> </span>--experiment<span class="w"> </span>comparison_cifar10

<span class="c1"># Visualize comparison results</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>visualize<span class="w"> </span>--experiment<span class="w"> </span>comparison_cifar10<span class="w"> </span>--plots<span class="w"> </span>all
</code></pre></div>
<p><strong>Model Comparison Features:</strong>
- <strong>Automated Training</strong>: Parallel training of multiple architectures
- <strong>Comprehensive Metrics</strong>: Accuracy, loss, training time, memory usage, inference speed
- <strong>Statistical Analysis</strong>: Mean, standard deviation, confidence intervals
- <strong>Visual Reports</strong>: Training curves, performance scatter plots, resource utilization
- <strong>Model Ranking</strong>: Automatic ranking based on multiple criteria
- <strong>Export Results</strong>: CSV, JSON, and PDF report generation
- <strong>Hardware Profiling</strong>: Jetson-specific performance characteristics</p>
<hr />
<h2 id="part-3-model-training-and-comparison"><strong>Part 3: Model Training and Comparison</strong><a class="headerlink" href="#part-3-model-training-and-comparison" title="Permanent link">&para;</a></h2>
<h3 id="31-train-multiple-architectures"><strong>3.1 Train Multiple Architectures</strong><a class="headerlink" href="#31-train-multiple-architectures" title="Permanent link">&para;</a></h3>
<p>Using the Jetson CNN Toolkit for comprehensive model comparison:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Train and compare multiple architectures</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>batch-train<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--models<span class="w"> </span>resnet18,mobilenet_v2,efficientnet_b0,custom_cnn<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span>cifar10<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--epochs<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save-best<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--generate-report

<span class="c1"># View training progress for all models</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>dashboard<span class="w"> </span>--experiment<span class="w"> </span>batch_cifar10
</code></pre></div>
<p><strong>Automated Training Pipeline:</strong>
- <strong>Parallel Training</strong>: Efficient resource utilization across multiple models
- <strong>Automatic Hyperparameter Tuning</strong>: Grid search and Bayesian optimization
- <strong>Progress Tracking</strong>: Real-time monitoring of all training processes
- <strong>Resource Management</strong>: Intelligent GPU memory allocation and cleanup
- <strong>Result Aggregation</strong>: Automatic collection and comparison of results</p>
<hr />
<h2 id="part-4-jetson-optimization-and-deployment"><strong>Part 4: Jetson Optimization and Deployment</strong><a class="headerlink" href="#part-4-jetson-optimization-and-deployment" title="Permanent link">&para;</a></h2>
<h3 id="41-performance-benchmarking"><strong>4.1 Performance Benchmarking</strong><a class="headerlink" href="#41-performance-benchmarking" title="Permanent link">&para;</a></h3>
<p>The toolkit provides comprehensive benchmarking capabilities:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Benchmark all trained models</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>benchmark<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--experiment<span class="w"> </span>batch_cifar10<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--metrics<span class="w"> </span>inference_time,memory_usage,fps,throughput<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input-size<span class="w"> </span><span class="m">224</span>,224<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--batch-sizes<span class="w"> </span><span class="m">1</span>,4,8,16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--iterations<span class="w"> </span><span class="m">100</span>

<span class="c1"># Generate detailed profiling report</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>profile<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>resnet18<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--detailed<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--export-traces

<span class="c1"># Compare optimization techniques</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>optimize-compare<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>resnet18<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--techniques<span class="w"> </span>fp16,tensorrt,quantization<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--benchmark
</code></pre></div>
<p><strong>Benchmarking Features:</strong>
- <strong>Comprehensive Metrics</strong>: Inference time, memory usage, FPS, throughput, power consumption
- <strong>Statistical Analysis</strong>: Mean, median, standard deviation, percentiles
- <strong>Batch Size Analysis</strong>: Performance scaling across different batch sizes
- <strong>Hardware Profiling</strong>: GPU utilization, memory bandwidth, thermal monitoring
- <strong>Optimization Comparison</strong>: Before/after optimization performance analysis
- <strong>Export Capabilities</strong>: JSON, CSV, and visual reports
- <strong>Real-time Monitoring</strong>: Live performance dashboard during benchmarking</p>
<hr />
<h2 id="part-5-real-time-deployment"><strong>Part 5: Real-time Deployment</strong><a class="headerlink" href="#part-5-real-time-deployment" title="Permanent link">&para;</a></h2>
<h3 id="51-deploy-best-model-for-real-time-inference"><strong>5.1 Deploy Best Model for Real-time Inference</strong><a class="headerlink" href="#51-deploy-best-model-for-real-time-inference" title="Permanent link">&para;</a></h3>
<p>The toolkit provides seamless real-time deployment capabilities:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Deploy the best performing model for real-time inference</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>deploy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--experiment<span class="w"> </span>batch_cifar10<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--select-best<span class="w"> </span>accuracy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--camera<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--display<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save-stats

<span class="c1"># Deploy with specific optimizations</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>deploy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>resnet18<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--optimize<span class="w"> </span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--camera<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--fps-target<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--resolution<span class="w"> </span>640x480

<span class="c1"># Batch inference on image directory</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>resnet18<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input-dir<span class="w"> </span>./test_images<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output-dir<span class="w"> </span>./results<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--batch-size<span class="w"> </span><span class="m">8</span>
</code></pre></div>
<p><strong>Real-time Deployment Features:</strong>
- <strong>Automatic Model Selection</strong>: Choose best model based on accuracy, speed, or custom criteria
- <strong>Camera Integration</strong>: Support for USB, CSI, and IP cameras
- <strong>Real-time Optimization</strong>: Dynamic batch sizing and frame skipping
- <strong>Performance Monitoring</strong>: Live FPS, latency, and resource utilization
- <strong>Output Options</strong>: Display, save images, export predictions
- <strong>Multi-format Support</strong>: Images, videos, and live camera streams
- <strong>Error Handling</strong>: Robust error recovery and logging</p>
<hr />
<h2 id="lab-deliverables"><strong>Lab Deliverables</strong><a class="headerlink" href="#lab-deliverables" title="Permanent link">&para;</a></h2>
<h3 id="required-deliverables"><strong>Required Deliverables</strong><a class="headerlink" href="#required-deliverables" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Model Implementation Report</strong></li>
<li>Implementation of at least 3 different CNN architectures</li>
<li>Training curves and accuracy comparisons</li>
<li>
<p>Analysis of parameter count vs performance trade-offs</p>
</li>
<li>
<p><strong>Optimization Analysis</strong></p>
</li>
<li>Benchmark results for all models</li>
<li>Memory usage analysis</li>
<li>Performance profiling reports</li>
<li>
<p>Jetson-specific optimization recommendations</p>
</li>
<li>
<p><strong>Real-time Deployment Demo</strong></p>
</li>
<li>Working real-time inference pipeline</li>
<li>Performance metrics (FPS, latency, accuracy)</li>
<li>
<p>Video demonstration or screenshots</p>
</li>
<li>
<p><strong>Technical Documentation</strong></p>
</li>
<li>Code documentation and comments</li>
<li>Setup instructions for reproduction</li>
<li>Troubleshooting guide</li>
</ol>
<h3 id="bonus-challenges"><strong>Bonus Challenges</strong><a class="headerlink" href="#bonus-challenges" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>üèÜ TensorRT Master</strong>
   <div class="highlight"><pre><span></span><code><span class="c1"># Convert best model to TensorRT engine using toolkit</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>optimize<span class="w"> </span>--model<span class="w"> </span>resnet18<span class="w"> </span>--technique<span class="w"> </span>tensorrt<span class="w"> </span>--target-speedup<span class="w"> </span><span class="m">50</span>
</code></pre></div></li>
<li>Achieve &gt;50% inference speedup</li>
<li>
<p>Maintain &lt;2% accuracy loss</p>
</li>
<li>
<p><strong>üß† Architecture Innovator</strong>
   <div class="highlight"><pre><span></span><code><span class="c1"># Create custom architecture with toolkit</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>create-custom<span class="w"> </span>--architecture-config<span class="w"> </span>custom_cnn.json<span class="w"> </span>--optimize-params
</code></pre></div></p>
</li>
<li>Design and implement custom CNN architecture</li>
<li>Achieve competitive accuracy with fewer parameters</li>
<li>
<p>Document design decisions</p>
</li>
<li>
<p><strong>‚ö° Speed Demon</strong>
   <div class="highlight"><pre><span></span><code><span class="c1"># Optimize for maximum FPS</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>optimize-speed<span class="w"> </span>--model<span class="w"> </span>resnet18<span class="w"> </span>--target-fps<span class="w"> </span><span class="m">30</span><span class="w"> </span>--enable-threading
</code></pre></div></p>
</li>
<li>Achieve &gt;30 FPS real-time inference</li>
<li>Implement multi-threading optimization</li>
<li>
<p>Add performance monitoring dashboard</p>
</li>
<li>
<p><strong>üéØ Accuracy Champion</strong>
   <div class="highlight"><pre><span></span><code><span class="c1"># Advanced training with ensemble methods</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>advanced-train<span class="w"> </span>--ensemble<span class="w"> </span>--knowledge-distillation<span class="w"> </span>--target-accuracy<span class="w"> </span><span class="m">90</span>
</code></pre></div></p>
</li>
<li>Achieve &gt;90% validation accuracy on CIFAR-10</li>
<li>Implement advanced training techniques</li>
<li>
<p>Use ensemble methods or knowledge distillation</p>
</li>
<li>
<p><strong>üîß Production Ready</strong>
   <div class="highlight"><pre><span></span><code><span class="c1"># Create production deployment package</span>
python3<span class="w"> </span>jetson_cnn_toolkit.py<span class="w"> </span>--mode<span class="w"> </span>package<span class="w"> </span>--model<span class="w"> </span>resnet18<span class="w"> </span>--include-monitoring<span class="w"> </span>--version-control
</code></pre></div></p>
</li>
<li>Create complete deployment package</li>
<li>Add error handling and logging</li>
<li>Implement model versioning and updates</li>
</ol>
<hr />
<h2 id="summary-and-next-steps"><strong>Summary and Next Steps</strong><a class="headerlink" href="#summary-and-next-steps" title="Permanent link">&para;</a></h2>
<h3 id="what-youve-accomplished"><strong>What You've Accomplished</strong><a class="headerlink" href="#what-youve-accomplished" title="Permanent link">&para;</a></h3>
<ul>
<li>‚úÖ Mastered the Jetson CNN Toolkit for multiple CNN architectures</li>
<li>‚úÖ Applied comprehensive training and validation frameworks using the toolkit</li>
<li>‚úÖ Performed Jetson-specific optimizations through automated tools</li>
<li>‚úÖ Deployed real-time inference pipelines with toolkit integration</li>
<li>‚úÖ Conducted performance benchmarking and analysis using built-in tools</li>
</ul>
<h3 id="key-takeaways"><strong>Key Takeaways</strong><a class="headerlink" href="#key-takeaways" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Architecture Matters</strong>: Different CNN architectures have distinct trade-offs between accuracy, speed, and memory usage</li>
<li><strong>Optimization is Critical</strong>: Jetson-specific optimizations can significantly improve performance</li>
<li><strong>Real-time Constraints</strong>: Production deployment requires careful balance of accuracy and speed</li>
<li><strong>Profiling is Essential</strong>: Understanding bottlenecks is key to effective optimization</li>
</ol>
<h3 id="next-steps"><strong>Next Steps</strong><a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h3>
<ol>
<li>Explore advanced optimization techniques (TensorRT, quantization)</li>
<li>Implement object detection and segmentation models</li>
<li>Study transformer-based vision models</li>
<li>Investigate edge AI deployment strategies</li>
<li>Learn about model compression and pruning techniques</li>
</ol>
<hr />
<p>üìå <strong>Summary</strong>
- ‚úÖ CNNs are essential for computer vision tasks
- ‚úÖ Jetson devices provide excellent edge AI capabilities
- ‚úÖ Multiple optimization strategies can improve performance
- ‚úÖ Real-time deployment requires careful engineering
- ‚úÖ Benchmarking and profiling guide optimization decisions</p>
<p>‚Üí <strong>Next</strong>: Transformers &amp; LLMs on Jetson
```</p>
<hr />
<p>‚∏ª</p>
<p>‚ö°Ô∏è TensorRT Acceleration on Jetson</p>
<p>üß© What is TensorRT?</p>
<p>TensorRT is NVIDIA‚Äôs high-performance deep learning inference optimizer and runtime engine. It converts trained models (ONNX, PyTorch, TensorFlow) into fast, deployable engines.</p>
<p>üîÅ Workflow: PyTorch ‚Üí ONNX ‚Üí TensorRT
    1.  Export model to ONNX</p>
<p>import torch
import torchvision.models as models</p>
<p>model = models.resnet18(pretrained=True)
model.eval()</p>
<p>dummy_input = torch.randn(1, 3, 224, 224)
torch.onnx.export(model, dummy_input, "resnet18.onnx", opset_version=11)</p>
<div class="highlight"><pre><span></span><code>2.  Convert ONNX to TensorRT engine
</code></pre></div>
<p>/opt/nvidia/onnxruntime/bin/trtexec --onnx=resnet18.onnx --saveEngine=resnet18.trt --explicitBatch</p>
<div class="highlight"><pre><span></span><code>3.  Run inference with TensorRT Python API
</code></pre></div>
<p>Use libraries like tensorrt, pycuda, or NVIDIA‚Äôs onnxruntime-gpu backend.</p>
<p>‚∏ª</p>
<p>üß™ Jetson Image Processing Tools</p>
<p>Tool/Library    Purpose
OpenCV (cv2)    Real-time image processing
Pillow (PIL)    Image loading and conversion
PyTorch/TensorRT    CNN inference
v4l2-ctl    Access and configure camera
GStreamer   Media pipeline and camera stream</p>
<p>‚∏ª</p>
<p>üß™ Lab: Classify Images with ResNet on Jetson</p>
<p>üéØ Objective</p>
<p>Run a pretrained CNN to classify local image data using PyTorch on Jetson. Then accelerate with TensorRT.</p>
<p>‚úÖ Setup</p>
<p>pip install torch torchvision pillow opencv-python onnx
sudo apt install python3-pycuda</p>
<p>üõ†Ô∏è Tasks
    1.  Run PyTorch-based ResNet inference on a test image
    2.  Export to ONNX and convert to TensorRT engine
    3.  Run and compare performance (fps / latency)</p>
<p>üìã Deliverables
    ‚Ä¢   Output of predicted class
    ‚Ä¢   Timing comparison between PyTorch and TensorRT
    ‚Ä¢   Screenshot of TensorRT engine build or trtexec results</p>
<p>‚∏ª</p>
<p>üß™ Lab: TensorRT-Based Image Classification in PyTorch Container</p>
<p>üéØ Objective</p>
<p>Use a Docker container with PyTorch and TensorRT pre-installed to classify an image using an optimized engine.</p>
<p>‚úÖ Container Setup</p>
<p>Use NVIDIA‚Äôs PyTorch container image with TensorRT:</p>
<p>docker run --rm -it --runtime nvidia \
  -v $(pwd):/workspace \
  nvcr.io/nvidia/pytorch:24.04-py3 /bin/bash</p>
<p>Inside container:</p>
<p>pip install pillow onnx</p>
<p>üõ†Ô∏è Tasks
    1.  Inside the container, download and convert a ResNet model to ONNX.
    2.  Run trtexec to convert ONNX ‚Üí TensorRT.
    3.  Write a Python script to load and run inference on the image using the onnxruntime-gpu or tensorrt backend.</p>
<p>Sample trtexec command</p>
<p>trtexec --onnx=resnet18.onnx --saveEngine=resnet18.trt --explicitBatch</p>
<p>Sample Python snippet</p>
<p>import onnxruntime as ort
from PIL import Image
import numpy as np</p>
<h1 id="preprocess-input">Preprocess input<a class="headerlink" href="#preprocess-input" title="Permanent link">&para;</a></h1>
<p>img = Image.open("cat.jpg").resize((224, 224))
img_np = np.asarray(img).astype(np.float32) / 255.0
img_np = img_np.transpose(2, 0, 1).reshape(1, 3, 224, 224)</p>
<h1 id="run-inference">Run inference<a class="headerlink" href="#run-inference" title="Permanent link">&para;</a></h1>
<p>session = ort.InferenceSession("resnet18.onnx")
outputs = session.run(None, {session.get_inputs()[0].name: img_np})
print("Predicted index:", np.argmax(outputs[0]))</p>
<p>üìã Deliverables
    ‚Ä¢   Screenshot of classification output
    ‚Ä¢   Screenshot of trtexec performance results
    ‚Ä¢   Brief reflection: how does TensorRT help?</p>
<p>‚∏ª</p>
<p>üìå Summary
    ‚Ä¢   CNNs are essential for vision-based AI
    ‚Ä¢   Jetson accelerates inference with CUDA + TensorRT
    ‚Ä¢   TensorRT reduces latency and improves FPS
    ‚Ä¢   PyTorch models can be deployed as optimized engines</p>
<p>‚Üí Next: Transformers &amp; LLMs</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>