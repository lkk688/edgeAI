# üéØ Jetson Object Detection Toolkit

A comprehensive all-in-one object detection toolkit for NVIDIA Jetson devices, supporting multiple state-of-the-art models with optional TensorRT acceleration.

## üöÄ Features

- **Multiple Detection Models**:
  - **Faster R-CNN**: High-accuracy two-stage detector
  - **YOLOv8**: Fast one-stage detector with TensorRT support
  - **OWL-ViT**: Zero-shot detection with text prompts
  - **GroundingDINO**: Advanced zero-shot detection with natural language

- **TensorRT Acceleration**: Automatic optimization for Jetson Orin (2-5x speedup)
- **Multiple Input Sources**: Camera, images, videos
- **Real-time Performance Monitoring**: FPS, inference time, statistics
- **Easy-to-use CLI Interface**: Simple command-line operation
- **Comprehensive Visualization**: Bounding boxes, confidence scores, class labels

## üìã Requirements

### Hardware
- NVIDIA Jetson device (Nano, Xavier, Orin)
- Camera (optional, for real-time detection)

### Software
```bash
# Base requirements
sudo apt update
sudo apt install python3-pip python3-dev

# Install PyTorch for Jetson
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install common dependencies
pip3 install opencv-python pillow numpy
```

### Model-Specific Dependencies

#### For YOLOv8
```bash
pip3 install ultralytics

# For TensorRT support
sudo apt install python3-libnvinfer-dev libnvinfer-bin
python3 -c "import tensorrt; print(f'TensorRT version: {tensorrt.__version__}')"
```

#### For OWL-ViT
```bash
pip3 install transformers timm
```

#### For GroundingDINO
```bash
# Clone and install GroundingDINO
git clone https://github.com/IDEA-Research/GroundingDINO.git
cd GroundingDINO
pip3 install -e .

# Download pre-trained weights
wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
```

## üõ†Ô∏è Installation

1. **Clone the repository**:
```bash
git clone <repository-url>
cd edgeAI
```

2. **Make the toolkit executable**:
```bash
chmod +x jetson_object_detection_toolkit.py
```

3. **Test installation**:
```bash
python3 jetson_object_detection_toolkit.py --help
```

## üéÆ Usage Examples

### 1. Real-time Camera Detection

#### YOLOv8 with TensorRT (Recommended for Jetson Orin)
```bash
# Basic YOLOv8 detection
python3 jetson_object_detection_toolkit.py --model yolo --source camera

# YOLOv8 with TensorRT acceleration
python3 jetson_object_detection_toolkit.py --model yolo --source camera --tensorrt

# Custom confidence and IoU thresholds
python3 jetson_object_detection_toolkit.py --model yolo --source camera --confidence 0.3 --iou 0.5
```

#### Faster R-CNN (High Accuracy)
```bash
python3 jetson_object_detection_toolkit.py --model faster-rcnn --source camera --confidence 0.7
```

#### Zero-Shot Detection with OWL-ViT
```bash
# Detect specific objects using text prompts
python3 jetson_object_detection_toolkit.py --model owl-vit --source camera --prompts "person,car,dog,laptop,cell phone"

# Custom prompts for specific use case
python3 jetson_object_detection_toolkit.py --model owl-vit --source camera --prompts "red backpack,bicycle,traffic light"
```

### 2. Image Processing

```bash
# Process single image with YOLOv8
python3 jetson_object_detection_toolkit.py --model yolo --source image.jpg --output result.jpg

# Zero-shot detection on image
python3 jetson_object_detection_toolkit.py --model owl-vit --source photo.png --prompts "person,car" --output detected.png

# High-accuracy detection with Faster R-CNN
python3 jetson_object_detection_toolkit.py --model faster-rcnn --source input.jpg --confidence 0.8
```

### 3. Video Processing

```bash
# Process video file with YOLOv8
python3 jetson_object_detection_toolkit.py --model yolo --source video.mp4 --output output_video.mp4

# Real-time video processing with TensorRT
python3 jetson_object_detection_toolkit.py --model yolo --source video.avi --tensorrt --confidence 0.25

# Zero-shot video detection
python3 jetson_object_detection_toolkit.py --model owl-vit --source input.mp4 --prompts "person,vehicle" --output result.mp4
```

### 4. Advanced Usage

#### Custom YOLOv8 Model
```bash
# Use custom trained YOLOv8 model
python3 jetson_object_detection_toolkit.py --model yolo --model-path custom_yolo.pt --source camera

# YOLOv8 large model with TensorRT
python3 jetson_object_detection_toolkit.py --model yolo --model-path yolov8l.pt --tensorrt --source camera
```

#### GroundingDINO (Advanced Zero-Shot)
```bash
# Note: Requires config and checkpoint files
python3 jetson_object_detection_toolkit.py --model grounding-dino \
    --config-path GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py \
    --checkpoint-path groundingdino_swint_ogc.pth \
    --source camera \
    --prompts "a person wearing a red shirt"
```

#### Multiple Camera Sources
```bash
# Use specific camera (camera ID)
python3 jetson_object_detection_toolkit.py --model yolo --source 0  # Default camera
python3 jetson_object_detection_toolkit.py --model yolo --source 1  # Second camera
```

## üéõÔ∏è Command Line Arguments

| Argument | Description | Default | Example |
|----------|-------------|---------|----------|
| `--model` | Detection model | Required | `yolo`, `faster-rcnn`, `owl-vit`, `grounding-dino` |
| `--source` | Input source | `camera` | `camera`, `image.jpg`, `video.mp4`, `0` |
| `--output` | Output path | None | `result.jpg`, `output.mp4` |
| `--device` | Compute device | `cuda` | `cuda`, `cpu` |
| `--tensorrt` | Enable TensorRT | False | `--tensorrt` |
| `--confidence` | Confidence threshold | 0.25 | `--confidence 0.5` |
| `--iou` | IoU threshold | 0.45 | `--iou 0.6` |
| `--prompts` | Text prompts (zero-shot) | None | `--prompts "person,car,dog"` |
| `--model-path` | Custom model path | None | `--model-path yolov8l.pt` |

## üîß TensorRT Optimization

### Automatic TensorRT Setup (YOLOv8)

The toolkit automatically handles TensorRT optimization when `--tensorrt` flag is used:

1. **ONNX Export**: Converts PyTorch model to ONNX format
2. **TensorRT Engine**: Creates optimized TensorRT engine with FP16 precision
3. **Performance Boost**: Achieves 2-5x speedup on Jetson devices

### Manual TensorRT Optimization

For advanced users, you can manually optimize models:

```bash
# Export YOLOv8 to ONNX
python3 -c "from ultralytics import YOLO; YOLO('yolov8n.pt').export(format='onnx')"

# Convert to TensorRT engine
trtexec --onnx=yolov8n.onnx --saveEngine=yolov8n_fp16.trt --fp16 --workspace=2048

# Advanced optimization for Jetson Orin
trtexec --onnx=yolov8n.onnx \
        --saveEngine=yolov8n_optimized.trt \
        --fp16 \
        --workspace=2048 \
        --minShapes=input:1x3x320x320 \
        --optShapes=input:1x3x640x640 \
        --maxShapes=input:1x3x1280x1280
```

## üìä Performance Benchmarks

### Jetson Orin Nano (8GB)

| Model | Input Size | FP32 FPS | TensorRT FP16 FPS | Speedup |
|-------|------------|----------|-------------------|----------|
| YOLOv8n | 640x640 | 25 | 65 | 2.6x |
| YOLOv8s | 640x640 | 18 | 45 | 2.5x |
| YOLOv8m | 640x640 | 12 | 28 | 2.3x |
| Faster R-CNN | 800x800 | 8 | N/A | N/A |
| OWL-ViT | 768x768 | 3 | N/A | N/A |

### Jetson Xavier NX

| Model | Input Size | FP32 FPS | TensorRT FP16 FPS | Speedup |
|-------|------------|----------|-------------------|----------|
| YOLOv8n | 640x640 | 15 | 35 | 2.3x |
| YOLOv8s | 640x640 | 10 | 22 | 2.2x |
| Faster R-CNN | 800x800 | 4 | N/A | N/A |

## üéØ Use Cases

### 1. Security and Surveillance
```bash
# Person detection for security cameras
python3 jetson_object_detection_toolkit.py --model yolo --source camera --confidence 0.4 --tensorrt

# Zero-shot detection for specific threats
python3 jetson_object_detection_toolkit.py --model owl-vit --source camera --prompts "weapon,knife,gun"
```

### 2. Autonomous Vehicles
```bash
# Vehicle and pedestrian detection
python3 jetson_object_detection_toolkit.py --model yolo --source camera --confidence 0.6 --tensorrt

# Traffic sign detection
python3 jetson_object_detection_toolkit.py --model owl-vit --source camera --prompts "stop sign,traffic light,speed limit sign"
```

### 3. Industrial Automation
```bash
# Quality control inspection
python3 jetson_object_detection_toolkit.py --model owl-vit --source camera --prompts "defect,crack,scratch"

# Inventory management
python3 jetson_object_detection_toolkit.py --model yolo --source camera --confidence 0.3
```

### 4. Retail Analytics
```bash
# Customer behavior analysis
python3 jetson_object_detection_toolkit.py --model faster-rcnn --source camera --confidence 0.7

# Product detection
python3 jetson_object_detection_toolkit.py --model owl-vit --source camera --prompts "bottle,can,package,box"
```

## üêõ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**:
   ```bash
   # Use smaller model or reduce batch size
   python3 jetson_object_detection_toolkit.py --model yolo --model-path yolov8n.pt
   ```

2. **TensorRT Installation Issues**:
   ```bash
   # Verify TensorRT installation
   python3 -c "import tensorrt; print(tensorrt.__version__)"
   
   # Reinstall if needed
   sudo apt install python3-libnvinfer-dev python3-libnvinfer
   ```

3. **Camera Access Issues**:
   ```bash
   # Check camera permissions
   sudo usermod -a -G video $USER
   
   # Test camera access
   v4l2-ctl --list-devices
   ```

4. **Model Download Issues**:
   ```bash
   # Pre-download models
   python3 -c "from ultralytics import YOLO; YOLO('yolov8n.pt')"
   ```

### Performance Optimization Tips

1. **Enable TensorRT**: Always use `--tensorrt` for YOLOv8 on Jetson Orin
2. **Adjust Confidence**: Lower confidence for more detections, higher for precision
3. **Camera Resolution**: Use 640x480 for real-time performance
4. **Model Size**: Use YOLOv8n for speed, YOLOv8l for accuracy
5. **Memory Management**: Close other applications to free GPU memory

## üìö Model Comparison

| Model | Speed | Accuracy | Memory | Zero-Shot | TensorRT |
|-------|-------|----------|--------|-----------|----------|
| **YOLOv8** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå | ‚úÖ |
| **Faster R-CNN** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚ùå | ‚ùå |
| **OWL-ViT** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚ùå |
| **GroundingDINO** | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚úÖ | ‚ùå |

## ü§ù Contributing

Contributions are welcome! Please feel free to submit issues, feature requests, or pull requests.

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- [Transformers (Hugging Face)](https://github.com/huggingface/transformers)
- [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO)
- [TorchVision](https://github.com/pytorch/vision)
- [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt)

---

**Happy Detecting! üéØ**